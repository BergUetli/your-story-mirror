import React, { useState, useCallback, useRef, useMemo, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { useAuth } from '@/contexts/AuthContext';
import { useConversation } from '@11labs/react';
import { useToast } from '@/hooks/use-toast';
import { useProfile } from '@/hooks/useProfile';
import { supabase } from '@/integrations/supabase/client';
import { ModernVoiceAgent } from '@/components/ModernVoiceAgent';
import { ParticleFaceCanvas } from '@/components/ParticleFaceCanvas';
import { intelligentPrompting } from '@/services/intelligentPrompting';
import { chunkMemoryContent } from '@/utils/memoryChunking';
import { narrativeAI, type NarrativeGenerationContext } from '@/services/narrativeAI';
import { logMemorySaving, logVoiceRecording, logArchiveDisplay } from '@/services/diagnosticLogger';
import { voiceRecordingService, testGuestRecording, testAuthenticatedRecording, checkDatabaseRecordings, checkGuestRecordings } from '@/services/voiceRecording';
import { conversationRecordingService } from '@/services/conversationRecording';
import { enhancedConversationRecordingService } from '@/services/enhancedConversationRecording';
import { soundEffects } from '@/services/soundEffects';
import { FirstConversationDialog } from '@/components/FirstConversationDialog';
import { userProfileService } from '@/services/userProfileService';
import { configurationService } from '@/services/configurationService';
// Dummy mode removed - always use real authentication
import { 
  Heart, 
  Clock, 
  Shield, 
  ArrowRight,
  Users,
  Lock,
  Sparkles,
  Music,
  Mic,
  Hexagon
} from 'lucide-react';
import { Link, useNavigate } from 'react-router-dom';

const Index = () => {
  const { user } = useAuth();
  const { toast } = useToast();
  const navigate = useNavigate();
  const { profile } = useProfile();
  
  // Always use real user - no dummy mode in production
  const effectiveUser = user;

  const [dbFirstName, setDbFirstName] = useState<string | null>(null);

  useEffect(() => {
    const fetchName = async () => {
      if (!effectiveUser?.id) return;
      try {
        const { data: userRow } = await supabase
          .from('users')
          .select('name')
          .eq('user_id', effectiveUser.id)
          .maybeSingle();
        if (userRow?.name) {
          setDbFirstName(String(userRow.name).trim().split(/\s+/)[0]);
          return;
        }
        const { data: profileRow } = await supabase
          .from('user_profiles')
          .select('preferred_name')
          .eq('user_id', effectiveUser.id)
          .maybeSingle();
        if (profileRow?.preferred_name) {
          setDbFirstName(String(profileRow.preferred_name).trim().split(/\s+/)[0]);
        }
      } catch (e) {
        console.warn('Name fetch fallback failed', e);
      }
    };
    fetchName();
  }, [effectiveUser?.id]);

  const displayFirstName = useMemo(() => {
    const nameCandidate = dbFirstName || profile?.name || (user as any)?.user_metadata?.full_name || (user as any)?.user_metadata?.name || '';
    const first = (nameCandidate || '').trim().split(/\s+/)[0];
    if (first) return first;
    const emailUser = user?.email?.split('@')[0];
    return emailUser ? emailUser.charAt(0).toUpperCase() + emailUser.slice(1) : 'Friend';
  }, [dbFirstName, profile?.name, user?.user_metadata, user?.email]);

  useEffect(() => {
    console.log('Greeting name resolution:', { dbFirstName, profileName: profile?.name, userMeta: user?.user_metadata, email: user?.email, displayFirstName });
  }, [displayFirstName, dbFirstName, profile?.name, user?.user_metadata, user?.email]);
  
  const [isConnecting, setIsConnecting] = useState(false);
  const noEndBeforeRef = useRef(0);
  const isTogglingRef = useRef(false);
  const lastConnectedAtRef = useRef(0);
  const retryCountRef = useRef(0);
  const startConversationRef = useRef<(isRetry?: boolean) => Promise<void>>();
  const reconnectTimeoutRef = useRef<number | null>(null);
  

  // Voice recording state
  const [recordingSessionId, setRecordingSessionId] = useState<string | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [recordingMode, setRecordingMode] = useState<'standard' | 'enhanced'>('enhanced'); // Use enhanced mode to capture both user and agent voice
  
  // View mode state (voice agent vs particle face)
  const [viewMode, setViewMode] = useState<'voice' | 'particle'>('voice');
  
  // Store authenticated user ID for voice recording
  const authenticatedUserIdRef = useRef<string | null>(null);
  
  // Enhanced conversation flow state
  const [isEndingConversation, setIsEndingConversation] = useState(false);
  const [pendingMemoryData, setPendingMemoryData] = useState<{
    title?: string;
    content?: string;
    needsCollection: boolean;
  } | null>(null);
  const [lastSavedMemoryId, setLastSavedMemoryId] = useState<string | null>(null);
  
  // Auto-end helpers
  const endConversationRef = useRef<(() => Promise<void> | void) | null>(null);
  const endScheduledRef = useRef(false);
  const scheduleEnd = (delayMs = 1500, reason = 'auto') => {
    if (Date.now() < noEndBeforeRef.current) return;
    if (endScheduledRef.current) return;
    endScheduledRef.current = true;
    setIsEndingConversation(true);
    console.log(`üõë Scheduling conversation end:`, reason);
    
    // Wait for Solin to finish speaking before ending
    const checkAndEnd = () => {
      if (conversation.isSpeaking) {
        console.log('‚è≥ Solin is still speaking, waiting...');
        setTimeout(checkAndEnd, 300); // Check every 300ms
      } else {
        console.log('‚úÖ Solin finished speaking, ending conversation after grace period...');
        // Give a small grace period after speaking stops to ensure audio finishes
        setTimeout(() => endConversationRef.current?.(), 1000);
      }
    };
    
    // Start checking after initial delay
    setTimeout(checkAndEnd, delayMs);
  };
  
  // First Conversation state
  const [needsFirstConversation, setNeedsFirstConversation] = useState(false);
  const [showFirstConversation, setShowFirstConversation] = useState(false);
  const [checkingProfile, setCheckingProfile] = useState(true);

  // Biography topics tool for collecting general information about the user
  const saveBiographyTopicTool = useCallback(async (parameters: {
    topic_category: string;
    topic_title: string;
    content: string;
    context_notes?: string;
  }) => {
    const handoffId = `biography-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üìñ [${handoffId}] BIOGRAPHY HANDOFF: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      // Validate required fields
      const { topic_category, topic_title, content } = parameters;
      
      if (!topic_category || !topic_title || !content) {
        logHandoff('‚ùå VALIDATION FAILED', { 
          hasCategory: !!topic_category, 
          hasTitle: !!topic_title, 
          hasContent: !!content 
        });
        return 'Missing required fields. Please provide category, title, and content for the biographical topic.';
      }

      logHandoff('2Ô∏è‚É£ VALIDATED', { 
        category: topic_category, 
        title: topic_title, 
        contentLength: content.length 
      });

      // Use real authenticated user ID only
      if (!effectiveUser?.id) {
        logHandoff('‚ùå NO USER ID', { message: 'User must be logged in to save biography topics' });
        return 'You must be logged in to save biographical information. Please sign in and try again.';
      }

      const userId = effectiveUser.id;
      
      logHandoff('3Ô∏è‚É£ SUBMITTING TO DATABASE', { userId, category: topic_category, title: topic_title });

      const { data, error } = await supabase
        .from('biography_entries')
        .insert([{
          user_id: userId,
          topic_category: topic_category,
          topic_title: topic_title,
          content: content,
          context_notes: parameters.context_notes || null,
          source: 'solin_conversation'
        }])
        .select()
        .single();

      if (error) {
        logHandoff('‚ùå DATABASE ERROR', { error: error.message, code: error.code });
        throw error;
      }

      logHandoff('4Ô∏è‚É£ DATABASE COMMITTED', { entryId: data.id, title: data.topic_title });

      toast({
        title: 'Biography Topic Saved',
        description: `"${topic_title}" added to your biographical profile.`,
        duration: 5000,
      });

      logHandoff('‚úÖ HANDOFF COMPLETE', {
        status: 'success',
        agentResponse: `Thank you for sharing about "${topic_title}". This biographical information enriches your life story beyond specific memories.`,
        note: 'Biography topic successfully saved'
      });

      return `Thank you for sharing about "${topic_title}". This biographical information has been saved and will help create a richer narrative of who you are as a person.`;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : 'Unknown error occurred';
      logHandoff('‚ùå HANDOFF FAILED', { error: errorMsg });
      
      toast({
        title: 'Failed to save biography topic',
        description: errorMsg,
        variant: 'destructive',
      });
      
      return `Failed to save biographical information: ${errorMsg}. Please try again.`;
    }
  }, [effectiveUser?.id, toast]);

  // Background function to update persistent biography when new memories are added
  const tryUpdatePersistentBiography = useCallback(async (userId: string, newMemory: any) => {
    try {
      // This runs in background - don't block the conversation
      console.log('üß© Attempting to update persistent biography with new memory:', newMemory.title);
      
      // Get current user profile and biography topics for context
      const [{ data: profile }, { data: topics }] = await Promise.all([
        supabase.from('users').select('*').eq('user_id', userId).single(),
        supabase.from('biography_entries').select('*').eq('user_id', userId)
      ]);

      // Get all memories for full context
      const { getGroupedMemories } = await import('@/utils/memoryGrouping');
      const allMemories = await getGroupedMemories(userId);
      
      const context: NarrativeGenerationContext = {
        user_profile: {
          name: profile?.name,
          birth_date: profile?.birth_date,
          birth_place: profile?.birth_place,
          current_location: profile?.current_location,
          age: profile?.birth_date ? new Date().getFullYear() - new Date(profile.birth_date).getFullYear() : undefined
        },
        memories: allMemories,
        biography_topics: (topics || []).map(t => ({
          topic_category: t.topic_category,
          topic_title: t.topic_title,
          content: t.content
        })),
        generation_preferences: {
          tone: 'reflective_optimistic',
          length: 'comprehensive',
          focus_themes: ['growth', 'relationships', 'achievements']
        }
      };

      // Try to insert the new memory into existing narrative
      await narrativeAI.insertMemoryIntoNarrative(userId, newMemory, context);
      
      console.log('‚úÖ Persistent biography updated with new memory');
      
    } catch (error) {
      // Don't throw - this is background processing
      console.log('üìù Background biography update failed (this is OK):', error);
    }
  }, []);

  const saveMemoryTool = useCallback(async (parameters: { 
    title: string; 
    content: string; 
    tags?: string[];
    memory_date?: string;
    memory_location?: string;
  }) => {
    const handoffId = `handoff-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üîÑ [${handoffId}] HANDOFF: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });
      logMemorySaving('info', 'memory_save_requested', { 
        handoffId, 
        userId: effectiveUser?.id,
        title: parameters?.title,
        contentLength: parameters?.content?.length,
        hasTags: !!parameters?.tags?.length,
        hasDate: !!parameters?.memory_date,
        hasLocation: !!parameters?.memory_location
      });

      // Validate required fields from tool call
      const title = parameters?.title?.trim();
      const content = parameters?.content?.trim();
      const memoryDate = parameters?.memory_date?.trim();
      const memoryLocation = parameters?.memory_location?.trim();
      
      if (!title || !content) {
        logHandoff('‚ùå VALIDATION FAILED', { title, hasContent: !!content });
        logMemorySaving('error', 'memory_validation_failed', { 
          handoffId, 
          hasTitle: !!title, 
          hasContent: !!content,
          userId: effectiveUser?.id
        });
        return 'Missing required fields: title and content. Please ask the user to provide both before saving.';
      }
      
      // Check if we have date, place, and title for timeline eligibility
      const hasDatePlaceTitle = !!(memoryDate && memoryLocation && title);
      logHandoff('2Ô∏è‚É£ VALIDATED', { 
        title, 
        contentLength: content.length, 
        hasDate: !!memoryDate, 
        hasLocation: !!memoryLocation,
        timelineEligible: hasDatePlaceTitle
      });
      
      // Parse and format memory_date to handle various formats
      let formattedDate: string | null = null;
      if (parameters.memory_date) {
        const dateStr = parameters.memory_date.trim();
        // 1) YYYY-MM-DD
        if (/^\d{4}-\d{2}-\d{2}$/.test(dateStr)) {
          formattedDate = dateStr;
        }
        // 2) YYYY-MM
        else if (/^(\d{4})-(\d{1,2})$/.test(dateStr)) {
          const [, y, m] = dateStr.match(/^(\d{4})-(\d{1,2})$/)!;
          formattedDate = `${y}-${m.padStart(2, '0')}-01`;
        }
        // 3) YYYY
        else if (/^\d{4}$/.test(dateStr)) {
          formattedDate = `${dateStr}-01-01`;
        } 
        // 4) Any natural date string
        else {
          try {
            const parsed = new Date(dateStr);
            if (!isNaN(parsed.getTime())) {
              formattedDate = parsed.toISOString().split('T')[0];
            }
          } catch (_) { /* ignore */ }

          // 5) As a last resort, extract a 4-digit year inside the string
          if (!formattedDate) {
            const yr = dateStr.match(/\b(\d{4})\b/);
            if (yr) formattedDate = `${yr[1]}-01-01`;
          }
        }

        logHandoff('3Ô∏è‚É£ DATE PARSED', { input: dateStr, formatted: formattedDate });
      }
      
      // Use real authenticated user ID only
      if (!effectiveUser?.id) {
        logHandoff('‚ùå NO USER ID', { effectiveUser, message: 'User must be logged in to save memories' });
        return 'You must be logged in to save memories. Please sign in and try again.';
      }
      
      const userId = effectiveUser.id;
      
      logHandoff('4Ô∏è‚É£ CHUNKING CONTENT', { userId, title, contentLength: content.length });

      // Chunk the memory content if it's too long
      const chunks = chunkMemoryContent(content);
      
      logHandoff('5Ô∏è‚É£ SUBMITTING TO DATABASE', { 
        userId, 
        title, 
        hasDate: !!formattedDate,
        chunksCount: chunks.length,
        memoryGroupId: chunks[0].memoryGroupId
      });

      // Insert all chunks
      const memoryInserts = chunks.map(chunk => ({
        user_id: userId,
        title: chunks.length > 1 ? `${title} (Part ${chunk.chunkSequence}/${chunk.totalChunks})` : title,
        text: chunk.content,
        tags: Array.isArray(parameters.tags) && parameters.tags.length > 0 ? parameters.tags : null,
        memory_date: formattedDate,
        memory_location: parameters.memory_location?.trim?.() || null,
        memory_group_id: chunk.memoryGroupId,
        chunk_sequence: chunk.chunkSequence,
        total_chunks: chunk.totalChunks,
        image_urls: null,
      }));

      logMemorySaving('info', 'memory_database_insert_attempt', {
        handoffId,
        userId,
        chunksToInsert: memoryInserts.length,
        memoryGroupId: chunks[0].memoryGroupId,
        sampleInsert: memoryInserts[0]
      });

      const { data, error } = await supabase
        .from('memories')
        .insert(memoryInserts)
        .select();

      if (error) {
        logHandoff('‚ùå DATABASE ERROR', { error: error.message, code: error.code });
        logMemorySaving('error', 'memory_database_insert_failed', {
          handoffId,
          userId,
          error: error.message,
          code: error.code,
          hint: error.hint,
          details: error.details,
          memoryGroupId: chunks[0].memoryGroupId
        });
        throw error;
      }

      logHandoff('6Ô∏è‚É£ DATABASE COMMITTED', { 
        chunksStored: data.length, 
        memoryGroupId: chunks[0].memoryGroupId,
        firstChunkId: data[0]?.id 
      });

      logMemorySaving('info', 'memory_database_insert_success', {
        handoffId,
        userId,
        chunksStored: data.length,
        memoryGroupId: chunks[0].memoryGroupId,
        insertedIds: data.map(d => d.id)
      });
      
      // Return success message with memory info
      const memoryGroupId = chunks[0].memoryGroupId;
      const memoryTitle = parameters.title; // Use original title without chunk numbering
      const primaryMemoryId = data[0]?.id; // First chunk ID for references
      
      logHandoff('7Ô∏è‚É£ SHOWING USER FEEDBACK', { 
        memoryGroupId, 
        memoryTitle, 
        timelineEligible: hasDatePlaceTitle,
        chunksCount: chunks.length 
      });
      
      // Different messaging based on whether memory will appear on timeline and chunking
      const chunkMessage = chunks.length > 1 ? ` (${chunks.length} parts)` : '';
      
      if (hasDatePlaceTitle) {
        toast({ 
          title: 'Memory saved to Timeline', 
          description: `"${memoryTitle}"${chunkMessage} has been preserved and will appear on your Timeline!`,
          duration: 5000,
        });
      } else {
        toast({ 
          title: 'Memory saved', 
          description: `"${memoryTitle}"${chunkMessage} has been preserved. Add date and location later to show on Timeline.`,
          duration: 5000,
        });
      }
      
      logHandoff('‚úÖ HANDOFF COMPLETE', { 
        status: 'success',
        timelineEligible: hasDatePlaceTitle,
        chunksCount: chunks.length,
        memoryGroupId,
        agentResponse: hasDatePlaceTitle 
          ? `Memory "${memoryTitle}"${chunkMessage} saved successfully and will appear on your Timeline!` 
          : `Memory "${memoryTitle}"${chunkMessage} saved successfully. It won't appear on the Timeline without a date and location, but you can still query it later.`,
        note: 'No auto-navigation - user can continue conversation'
      });
      
      // Update conversation state safely (not passed to ElevenLabs)
      setConversationState(prev => ({
        ...prev,
        recentMemories: [
          { id: primaryMemoryId, title: memoryTitle, timestamp: new Date().toISOString() },
          ...prev.recentMemories.slice(0, 4) // Keep only 5 most recent
        ],
        totalMemoriesSaved: prev.totalMemoriesSaved + 1,
        recentTopics: [
          ...new Set([title, ...prev.recentTopics.slice(0, 9)]) // Keep unique topics, max 10
        ]
      }));

      // Add memory linkage to any active recording
      if (isRecording && recordingSessionId) {
        try {
          if (recordingMode === 'enhanced') {
            // Track in enhanced recorder - this persists in memory until recording stops
            enhancedConversationRecordingService.addEnhancedMemory(primaryMemoryId, memoryTitle);
            console.log('üìù Memory linked to enhanced recording session (will be saved when recording stops)');
            
            // NOTE: Don't try to update DB here - the row doesn't exist yet
            // It will be created with the correct titles when recording stops
          } else {
            // Legacy recorder
            voiceRecordingService.addMemoryId(primaryMemoryId);
            // Try optimistic DB update (may fail if row doesn't exist yet)
            try {
              await supabase
                .from('voice_recordings')
                .update({ 
                  memory_ids: [primaryMemoryId],
                  memory_titles: [memoryTitle],
                  conversation_summary: memoryTitle
                })
                .eq('session_id', recordingSessionId);
              console.log('üìù Linked memory to standard recording with title');
            } catch (updateError) {
              console.log('‚ÑπÔ∏è Could not update DB (row may not exist yet):', updateError);
            }
          }
        } catch (error) {
          console.error('‚ö†Ô∏è Failed to link memory to recording:', error);
        }
      }

      // Play success chime for memory save
      try {
        await soundEffects.playMemorySaveChime();
      } catch (error) {
        console.warn('Sound effect failed:', error);
      }

      // Trigger narrative AI integration for biography updates
      // This happens asynchronously in the background
      tryUpdatePersistentBiography(userId, {
        memory_group_id: chunks[0].memoryGroupId,
        id: primaryMemoryId,
        title: memoryTitle,
        text: content,
        memory_date: formattedDate,
        memory_location: parameters.memory_location?.trim?.() || null,
        created_at: new Date().toISOString(),
        updated_at: new Date().toISOString()
      });
      
      // Generate intelligent follow-up questions after saving memory
      generateIntelligentSuggestions({ id: primaryMemoryId, title: memoryTitle, text: content, created_at: new Date().toISOString() });
      
      // Store last saved memory ID for potential Timeline redirect
      setLastSavedMemoryId(primaryMemoryId);
      
      // Check if this is part of ending conversation flow
      if (isEndingConversation && hasDatePlaceTitle) {
        // Auto-redirect to Timeline page with memory highlighting
        setTimeout(() => {
          navigate(`/timeline?highlight=${primaryMemoryId}&new=true`);
        }, 2000);
        
        return `Perfect! Memory "${memoryTitle}"${chunkMessage} saved successfully! I'm taking you to your Timeline now where you'll see it appear. Thank you for sharing your memories with me!`;
      }
      
      // Return appropriate response based on timeline eligibility
      if (hasDatePlaceTitle) {
        return `Memory "${memoryTitle}"${chunkMessage} saved successfully and will appear on your Timeline! You can continue sharing stories or explore other memories.`;
      } else {
        return `Memory "${memoryTitle}"${chunkMessage} saved successfully! Since it doesn't have a specific date and location, it won't appear on the Timeline but you can still query it later. Would you like to add more details or continue with other stories?`;
      }
    } catch (error) {
      logHandoff('‚ùå HANDOFF FAILED', { 
        error: error instanceof Error ? error.message : 'Unknown error',
        stack: error instanceof Error ? error.stack : undefined
      });
      
      const errObj = (typeof error === 'object' && error) ? (error as any) : null;
      const errorMsg = errObj?.message || errObj?.error_description || errObj?.hint || JSON.stringify(errObj) || 'Unknown error';
      
      toast({
        title: 'Failed to save memory',
        description: errorMsg,
        variant: 'destructive',
      });
      
      return `Failed to save memory: ${errorMsg}. Please try again or ask the user to provide the date in a different format.`;
    }
  }, [effectiveUser?.id, toast]);

  const onConnectCb = useCallback(async () => {
    const timestamp = new Date().toISOString();
    console.log(`üîå CONNECTION HANDOFF: ‚úÖ CONNECTED @ ${timestamp}`, {
      status: 'ElevenLabs voice agent connected',
      retryCount: retryCountRef.current
    });
    
    noEndBeforeRef.current = Date.now() + 2000;
    lastConnectedAtRef.current = Date.now();
    
    // Clear any pending reconnect timeouts when a connection succeeds
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current);
      reconnectTimeoutRef.current = null;
    }

    // Initialize conversation state for this session with greeting phase
    setConversationState(prev => ({
      ...prev,
      sessionStartTime: timestamp,
      // Reset for new session
      recentTopics: [],
      recentMemories: [],
      totalMemoriesSaved: 0,
      sessionMode: 'unset',
      conversationPhase: 'greeting'
    }));
    
    // Clear any previous memory ID from last session
    setLastSavedMemoryId(null);
    
    // Start voice recording if user is authenticated
    try {
      console.log('üé§üîç DEBUG: Checking user context for voice recording...');
      console.log('üë§ effectiveUser:', effectiveUser);
      console.log('üë§ user from useAuth:', user);
      console.log('üë§ authenticatedUserIdRef.current:', authenticatedUserIdRef.current);
      console.log('üë§ effectiveUser?.id:', effectiveUser?.id);
      console.log('üë§ user?.id:', user?.id);
      
      // Use the authenticated user ID from the ref (set during startConversation)
      // This is more reliable than React state during the callback
      const recordingUserId = authenticatedUserIdRef.current || user?.id || effectiveUser?.id;
      
      if (recordingUserId) {
        console.log(`üé§ Starting ${recordingMode} conversation recording for authenticated user:`, recordingUserId);
        
        let sessionId: string;
        if (recordingMode === 'enhanced') {
              sessionId = await enhancedConversationRecordingService.startEnhancedRecording(
                recordingUserId, 
                'elevenlabs_conversation',
                { 
                  enableSystemAudio: false, // DOM observer captures ElevenLabs audio elements automatically
                  microphoneGain: 1.0,
                  systemAudioGain: 0.85
                }
              );
        } else {
          sessionId = await conversationRecordingService.startConversationRecording(recordingUserId, 'elevenlabs_conversation');
        }
        
        setRecordingSessionId(sessionId);
        setIsRecording(true);
        console.log(`‚úÖ ${recordingMode} conversation recording started successfully:`, sessionId);

        // Prompt for screen sharing to capture AI audio (optional)
        if (recordingMode === 'enhanced') {
          console.log('üí° Enhanced recording started - microphone only');
          console.log('üñ•Ô∏è To record AI voice too, enable screen/tab sharing when prompted');
          
          // Optionally prompt for screen sharing after a short delay
          setTimeout(async () => {
            if (isRecording) {
              try {
                await enhancedConversationRecordingService.enableScreenSharing();
                toast({
                  title: 'Full Recording Active',
                  description: 'Now recording both your voice and AI responses',
                });
              } catch (e) {
                console.log('‚ÑπÔ∏è Screen sharing not enabled - recording microphone only');
                toast({
                  title: 'Microphone-Only Recording',
                  description: 'Recording your voice. AI responses won\'t be captured without screen sharing.',
                  variant: 'default'
                });
              }
            }
          }, 2000); // Wait 2 seconds before prompting
        }
        
        // Add periodic status logging
        const statusInterval = setInterval(() => {
          if (recordingMode === 'enhanced') {
            const status = enhancedConversationRecordingService.getEnhancedRecordingStatus();
            console.log('üé¨ Enhanced Recording Status:', status);
          } else {
            const status = conversationRecordingService.getRecordingStatus();
            console.log('üé¨ Standard Recording Status:', status);
          }
        }, 10000); // Log every 10 seconds
        
        // Clean up interval when conversation ends
        setTimeout(() => clearInterval(statusInterval), 300000); // Max 5 minutes
      } else {
        console.warn('‚ö†Ô∏è No authenticated user found - voice recording skipped');
        console.log('üîç Auth debug:', { 
          refUserId: authenticatedUserIdRef.current,
          user, 
          effectiveUser, 
          hasUser: !!user, 
          hasEffectiveUser: !!effectiveUser,
          userType: typeof user,
          effectiveUserType: typeof effectiveUser
        });
      }
    } catch (error) {
      console.error('‚ö†Ô∏è Failed to start voice recording (continuing without):', error);
      // Continue without recording - not critical
    }
    
    // Generate conversation starters based on user's memory history
    setTimeout(() => generateIntelligentSuggestions(), 1000);
    
    // Do not reset retryCountRef here; only reset after a stable connection duration
    // retryCountRef will be reset in onDisconnect if the session lasted long enough
    toast({ 
      title: 'Connected to Solin', 
      description: isRecording 
        ? 'Recording started - Solin will ask what type of conversation you\'d like'
        : 'Solin will ask what type of conversation you\'d like to have'
    });
  }, [toast, effectiveUser?.id, user?.id, isRecording]);

  const onDisconnectCb = useCallback(async () => {
    const elapsed = Date.now() - lastConnectedAtRef.current;
    const timestamp = new Date().toISOString();
    
    console.log(`üîå CONNECTION HANDOFF: üëã DISCONNECTED @ ${timestamp}`, {
      status: 'ElevenLabs voice agent disconnected',
      sessionDuration: `${elapsed}ms`,
      retryCount: retryCountRef.current,
      wasRecording: isRecording
    });

    // If we intentionally ended the conversation, don't auto-retry
    if (isEndingConversation || endScheduledRef.current) {
      console.log('üõë Skipping auto-retry: intentional end detected');
      retryCountRef.current = 0;
      endScheduledRef.current = false;
      setIsEndingConversation(false);
      toast({ 
        title: 'Disconnected', 
        description: 'Voice session ended',
      });
      return;
    }
    
    // Stop voice recording if active
    if (isRecording && recordingSessionId) {
      try {
        console.log(`üõë Stopping ${recordingMode} conversation recording due to disconnect...`);
        if (recordingMode === 'enhanced') {
          await enhancedConversationRecordingService.stopEnhancedRecording();
        } else {
          await conversationRecordingService.stopConversationRecording();
        }
        setIsRecording(false);
        setRecordingSessionId(null);
        console.log(`‚úÖ ${recordingMode} conversation recording stopped and saved`);
      } catch (error) {
        console.error(`‚ö†Ô∏è Failed to stop ${recordingMode} voice recording:`, error);
        setIsRecording(false);
        setRecordingSessionId(null);
      }
    }

    // AUTO-SAVE: Try to save conversation content when disconnected
    // Only if this wasn't an immediate disconnect
    const veryQuickDisconnect = elapsed < 1000;
    const earlyDisconnect = elapsed < 5000;
    
    if (!veryQuickDisconnect) {
      try {
        await autoSaveConversationContent();
      } catch (error) {
        console.error('‚ùå Auto-save on disconnect failed:', error);
      }
    }

    // Do NOT auto-retry to avoid reconnect loops; surface the issue and let user retry manually
    if (earlyDisconnect) {
      console.warn('‚õî Early disconnect detected; auto-retry disabled to prevent loops.');
      toast({
        title: 'Connection unstable',
        description: 'The voice agent disconnected unexpectedly. Tap Start Conversation to try again.',
        variant: 'destructive',
      });
    } else if (elapsed >= 10000) {
      // Stable session (10+ seconds): reset retry counter
      retryCountRef.current = 0;
    }

    toast({ 
      title: 'Disconnected', 
      description: isRecording 
        ? 'Voice session ended and recording saved'
        : 'Voice session ended' 
    });
  }, [toast, isRecording, recordingSessionId, isEndingConversation, isConnecting]);

  const onErrorCb = useCallback((error: unknown) => {
    toast({
      title: 'Connection failed',
      description: typeof error === 'string' ? error : 'Please try again',
      variant: 'destructive',
    });
  }, [toast]);

  const [conversationMessages, setConversationMessages] = useState<Array<{role: string, text: string}>>([]);
  
  // Safe conversation state management - NOT passed to ElevenLabs to avoid crashes
  const [conversationState, setConversationState] = useState<{
    recentTopics: string[];
    recentMemories: Array<{id: string, title: string, timestamp: string}>;
    sessionStartTime: string;
    totalMemoriesSaved: number;
    userInteractionStyle: 'brief' | 'detailed';
    userMemoryProfile: any;
    suggestedQuestions: string[];
    sessionMode: 'unset' | 'daily_journal' | 'memory_creation' | 'memory_browsing' | 'general_chat';
    conversationPhase: 'greeting' | 'mode_selection' | 'active_conversation' | 'wrap_up';
    activeMemoryId?: string; // Currently selected memory for editing
  }>({
    recentTopics: [],
    recentMemories: [],
    sessionStartTime: '',
    totalMemoriesSaved: 0,
    userInteractionStyle: 'detailed',
    userMemoryProfile: null,
    suggestedQuestions: [],
    sessionMode: 'unset',
    conversationPhase: 'greeting'
  });

  const retrieveMemoryTool = useCallback(async (parameters: { query?: string; limit?: number }) => {
    try {
      const q = parameters?.query?.trim() ?? '';
      const maxResults = parameters?.limit ?? 5;
      console.log('üîç Solin searching memories:', q, 'limit:', maxResults);
      if (!user?.id) return 'No user session; unable to access memories.';

      let query = supabase
        .from('memories')
        .select('id,title,created_at')
        .eq('user_id', effectiveUser.id)
        .order('created_at', { ascending: false })
        .limit(maxResults);

      // Only apply search filter if query is provided
      if (q) {
        const escaped = q.replace(/%/g, '%25').replace(/\\/g, '\\\\').replace(/"/g, '\\"');
        const orFilter = `title.ilike.%${escaped}%,text.ilike.%${escaped}%`;
        query = query.or(orFilter);
      }

      const { data, error } = await query;

      if (error) {
        console.error('Supabase retrieve error:', error);
        return 'Error retrieving memories.';
      }
      if (!data || data.length === 0) return 'No matching memories found.';

      // Return titles with IDs so agent can request details
      const result = data
        .map((m, i) => `${i + 1}. "${m.title}" (ID: ${m.id}, ${new Date(m.created_at as string).toLocaleDateString()})`)
        .join('\n');
      // Smart response based on conversation state
      let contextualNote = '';
      if (conversationState.recentMemories.length > 0) {
        const recentTitles = conversationState.recentMemories.map(m => m.title);
        const hasRecentMatch = data.some(m => recentTitles.includes(m.title));
        if (hasRecentMatch) {
          contextualNote = '\n\nüí¨ Note: Some of these were discussed recently in our conversation.';
        }
      }
      
      return `Found ${data.length} matching memories:\n${result}\n\nTo get full details, use get_memory_details with the ID.${contextualNote}`;
    } catch (error) {
      console.error('Error retrieving memory:', error);
      return 'Unable to retrieve memories at this time.';
    }
  }, [effectiveUser, conversationState.recentTopics, conversationState.recentMemories]);



  const getMemoryDetailsTool = useCallback(async (parameters: { memory_id: string }) => {
    try {
      const memoryId = parameters?.memory_id?.trim();
      console.log('üìñ Solin requesting details for memory:', memoryId);
      if (!user?.id) return 'No user session; unable to access memory details.';
      if (!memoryId) return 'Memory ID is required.';

      const { data, error } = await supabase
        .from('memories')
        .select('title,text,memory_date,memory_location,tags,created_at')
        .eq('id', memoryId)
        .eq('user_id', effectiveUser.id)
        .maybeSingle();

      if (error) {
        console.error('Supabase details error:', error);
        return 'Error retrieving memory details.';
      }
      if (!data) return 'Memory not found or access denied.';

      let details = `Title: ${data.title}\n\nContent: ${data.text}`;
      if (data.memory_date) details += `\n\nDate: ${new Date(data.memory_date).toLocaleDateString()}`;
      if (data.memory_location) details += `\nLocation: ${data.memory_location}`;
      if (data.tags && data.tags.length > 0) details += `\nTags: ${data.tags.join(', ')}`;
      
      // Add context if this memory was recently saved
      const isRecentlySaved = conversationState.recentMemories.some(m => m.id === memoryId);
      if (isRecentlySaved) {
        details += `\n\nüéÜ Note: This memory was saved during our current conversation.`;
      }
      
      return details;
    } catch (error) {
      console.error('Error getting memory details:', error);
      return 'Unable to retrieve memory details at this time.';
    }
  }, [effectiveUser, conversationState.recentMemories]);

  // Biography editing tool for Solin integration
  const editBiographyTool = useCallback(async (parameters: {
    modification_request: string;
    focus_area?: string;
    tone_adjustment?: string;
  }) => {
    const handoffId = `biography-edit-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`‚úçÔ∏è [${handoffId}] BIOGRAPHY EDIT: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'Solin voice agent', parameters });

      const { modification_request } = parameters;
      
      if (!modification_request?.trim()) {
        logHandoff('‚ùå VALIDATION FAILED', { hasRequest: !!modification_request });
        return 'Please specify what changes you would like me to make to your biography.';
      }

      if (!effectiveUser?.id) {
        logHandoff('‚ùå NO USER ID', { message: 'User must be logged in to edit biography' });
        return 'You must be logged in to edit your biography. Please sign in and try again.';
      }

      const userId = effectiveUser.id;
      
      logHandoff('2Ô∏è‚É£ STARTING REGENERATION', { userId, request: modification_request });

      // Get current context for regeneration
      const [{ data: profile }, { data: topics }] = await Promise.all([
        supabase.from('users').select('*').eq('user_id', userId).single(),
        supabase.from('biography_entries').select('*').eq('user_id', userId)
      ]);

      const { getGroupedMemories } = await import('@/utils/memoryGrouping');
      const memories = await getGroupedMemories(userId);
      
      const context: NarrativeGenerationContext = {
        user_profile: {
          name: profile?.name,
          birth_date: profile?.birth_date,
          birth_place: profile?.birth_place,
          current_location: profile?.current_location,
          age: profile?.birth_date ? new Date().getFullYear() - new Date(profile.birth_date).getFullYear() : undefined
        },
        memories,
        biography_topics: (topics || []).map(t => ({
          topic_category: t.topic_category,
          topic_title: t.topic_title,
          content: t.content
        })),
        generation_preferences: {
          tone: parameters.tone_adjustment as any || 'reflective_optimistic',
          length: 'comprehensive',
          focus_themes: parameters.focus_area ? [parameters.focus_area] : ['growth', 'relationships', 'achievements']
        }
      };

      // Regenerate biography with user's modification request
      const updatedBiography = await narrativeAI.regenerateBiographyWithPrompt(
        userId,
        modification_request.trim(),
        context
      );

      logHandoff('3Ô∏è‚É£ BIOGRAPHY REGENERATED', { biographyId: updatedBiography.id });

      toast({
        title: 'Biography Updated',
        description: 'Your story has been regenerated based on your request',
        duration: 5000,
      });

      logHandoff('‚úÖ HANDOFF COMPLETE', {
        status: 'success',
        biographyId: updatedBiography.id,
        chaptersCount: updatedBiography.chapters.length,
        agentResponse: `I've successfully updated your biography based on your request: "${modification_request}". The changes have been applied throughout your story.`
      });

      return `I've successfully updated your biography based on your request. Your story has been regenerated with the changes you requested: "${modification_request}". You can view the updated version on your Story page.`;

    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : 'Unknown error occurred';
      logHandoff('‚ùå HANDOFF FAILED', { error: errorMsg });
      
      toast({
        title: 'Failed to update biography',
        description: errorMsg,
        variant: 'destructive',
      });
      
      return `I wasn't able to update your biography: ${errorMsg}. Please try again or let me know if you need help with a different approach.`;
    }
  }, [effectiveUser?.id, toast]);

  // Generate intelligent follow-up questions based on user's memory patterns
  const generateIntelligentSuggestions = useCallback(async (latestMemory?: any) => {
    try {
      if (!effectiveUser?.id) {
        console.log('üß† No user ID, using fallback suggestions');
        // Provide fallback suggestions without user data
        const fallbackSuggestions = [
          "What's a moment from your past that always makes you smile?",
          "Tell me about a place that holds special meaning for you.",
          "What's something you've learned about yourself recently?"
        ];
        setConversationState(prev => ({
          ...prev,
          suggestedQuestions: fallbackSuggestions
        }));
        return;
      }
      
      // Fetch user's recent memories to analyze patterns
      console.log('üß† Fetching memories for intelligent analysis...');
      const { data: memories, error } = await supabase
        .from('memories')
        .select('id,title,text,memory_date,memory_location,tags,created_at')
        .eq('user_id', effectiveUser.id)
        .order('created_at', { ascending: false })
        .limit(20);
      
      if (error) {
        console.warn('‚ö†Ô∏è Could not fetch memories for analysis:', error);
        // Use basic suggestions if database fails
        const basicSuggestions = [
          "What's a childhood memory that shaped who you are?",
          "Tell me about someone who had a big impact on your life.",
          "What's a moment you'd want your family to remember?"
        ];
        setConversationState(prev => ({
          ...prev,
          suggestedQuestions: basicSuggestions
        }));
        return;
      }
      
      if (!memories || memories.length === 0) {
        console.log('üß† No memories found, using starter suggestions');
        const starterSuggestions = [
          "What's your earliest childhood memory?",
          "Tell me about your hometown and what made it special.",
          "What's a family tradition that means a lot to you?"
        ];
        setConversationState(prev => ({
          ...prev,
          suggestedQuestions: starterSuggestions
        }));
        return;
      }
      
      // Analyze user's memory profile
      console.log(`üß† Analyzing ${memories.length} memories for patterns...`);
      const profile = intelligentPrompting.analyzeMemoryProfile(memories);
      
      let suggestions: string[] = [];
      
      if (latestMemory) {
        // Generate follow-up questions for the just-saved memory
        suggestions = intelligentPrompting.generateFollowUpQuestions(
          latestMemory,
          profile,
          conversationState.recentTopics
        );
      } else {
        // Generate conversation starters
        suggestions = intelligentPrompting.generateConversationStarters(profile);
      }
      
      // Update state with profile and suggestions
      setConversationState(prev => ({
        ...prev,
        userMemoryProfile: profile,
        suggestedQuestions: suggestions
      }));
      
      console.log(`üß† Generated ${suggestions.length} intelligent suggestions:`, suggestions);
      
    } catch (error) {
      console.error('‚ùå Error generating intelligent suggestions:', error);
      // Always provide fallback suggestions
      const fallbackSuggestions = [
        "What's something that happened recently that you'd like to remember?",
        "Tell me about a person who influenced your life.",
        "What's a decision you made that you're proud of?"
      ];
      setConversationState(prev => ({
        ...prev,
        suggestedQuestions: fallbackSuggestions
      }));
    }
  }, [effectiveUser, conversationState.recentTopics, supabase]);

  // Static agent instructions - no memory context to avoid filling context window
  const agentInstructions = `You are Solin, a warm AI voice companion helping users preserve their life stories. You have access to these powerful tools:

1. initialize_session: IMPORTANT - Use this FIRST when starting a conversation to offer upfront options (daily_journal, memory_creation, memory_browsing, or general_chat).
2. save_memory: Save new memories when users share stories. For Timeline appearance: needs title, content, date (memory_date), and location (memory_location).
3. save_biography_topic: Save general biographical information about the user (personality, background, beliefs, etc.).
4. browse_memories: Search and browse existing memories conversationally. Use for memory exploration and finding specific memories.
5. get_memory_details: Get full details of a specific memory by ID.
6. edit_memory: Modify existing memories verbally. Can add content, replace sections, or completely update memories.
7. voice_search: NEW - Find and replay past conversations by searching voice recordings. Users can search for "conversations about family" or "when I talked about vacation".
8. play_voice_recording: NEW - Play back specific voice recordings, show transcripts, or provide summaries of past conversations.
9. retrieve_memory: Basic memory search (use browse_memories for better experience).
10. get_conversation_suggestions: Get intelligent, personalized questions based on session mode and user's patterns.
11. close_conversation: Use when user wants to end the conversation. Handles proper session closure.
12. edit_biography: Help users modify their AI-generated life story.

VOICE RECORDING & SEARCH (NEW):
- All conversations are automatically recorded and stored with transcripts
- Users can search their voice history: "Find conversations about my mom" or "When did I talk about travel?"
- Use voice_search to find relevant conversations, then play_voice_recording to access them
- Offer transcript reading, conversation summaries, or audio playback
- Voice recordings are linked to memories created during those conversations

CONVERSATION INITIALIZATION (CRITICAL):
- At the start of EVERY conversation, use initialize_session tool to offer upfront options
- Present 4 choices: "daily journal entry", "new memory preservation", "browse/edit existing memories", or "general conversation"
- Based on their choice, tailor all subsequent interactions to that mode

SESSION MODES:
- daily_journal: Focus on today's events, reflections, current thoughts, what stood out from their day
- memory_creation: Focus on specific past experiences, stories worth preserving, detailed memories  
- memory_browsing: Browse, search, and edit existing memories. Use browse_memories and edit_memory tools actively.
- general_chat: Open exploration of life experiences, can mix daily reflections with memories

MEMORY & VOICE INTERACTION FLOW:
When users want to work with existing content:
1. Use browse_memories to find text-based memories
2. Use voice_search to find past conversations
3. Offer to read transcripts, play recordings, or show memory details
4. Suggest adding to memories with edit_memory (edit_type: "add_to")
5. Help modify memories with edit_memory (edit_type: "modify" or "replace_section")
6. Connect voice recordings to related memories when relevant

CONVERSATION FLOW:
1. ALWAYS start with initialize_session to get user's preference
2. Use get_conversation_suggestions with type="starter" after mode selection
3. In memory_browsing mode: actively use browse_memories, voice_search, and suggest interactions
4. After memories/topics are shared, use get_conversation_suggestions with type="followup"
5. If conversation stalls, use get_conversation_suggestions with type="reflection"
6. When saving memories, gently ask for date/location if missing

VOICE SEARCH EXAMPLES:
- "Find conversations where I talked about my mother"
- "When did I discuss my vacation plans?"
- "Show me recordings from last week"
- "What did I say about work stress?"

Keep responses brief and conversational. Make memory and voice interaction feel natural and powerful.`;

  // Enhanced conversation closing tool for ElevenLabs agent communication
  const closeConversationTool = useCallback(async (parameters: {
    summary?: string;
    memory_count?: number;
    final_message?: string;
  }) => {
    const handoffId = `close-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üîö [${handoffId}] CLOSE HANDOFF: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED CLOSE REQUEST', { 
        source: 'ElevenLabs voice agent', 
        parameters,
        sessionMemories: conversationState.totalMemoriesSaved
      });

      const summary = parameters?.summary || 'User requested to end conversation';
      const memoryCount = parameters?.memory_count || conversationState.totalMemoriesSaved;
      const finalMessage = parameters?.final_message || 'Thank you for sharing your memories!';

      logHandoff('2Ô∏è‚É£ PREPARED CLOSURE', { summary, memoryCount, finalMessage });

      // Show user feedback about conversation closure
      toast({ 
        title: 'Conversation Saved', 
        description: `Session ended. ${memoryCount} memories preserved.`,
        duration: 5000,
      });

      logHandoff('3Ô∏è‚É£ USER NOTIFIED', { status: 'toast_shown' });

      // Schedule actual session end shortly after the farewell completes
      scheduleEnd(1500, 'agent_tool_close_conversation');

      logHandoff('üéØ HANDOFF COMPLETE', { 
        status: 'success',
        agentResponse: 'Conversation will be closed shortly. Thank you for using Solin!',
        note: 'ElevenLabs agent informed about conversation closure'
      });

      return `${finalMessage} Your conversation will end now. You can always start a new one anytime.`;
    } catch (error) {
      logHandoff('‚ùå CLOSE HANDOFF FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return 'Error closing conversation. Please try again or close manually.';
    }
  }, [toast, conversationState.totalMemoriesSaved]);

  // Session initialization tool for conversation mode selection
  const initializeSessionTool = useCallback(async (parameters: {
    session_mode: 'daily_journal' | 'memory_creation' | 'memory_browsing' | 'general_chat';
    user_preference?: string;
  }) => {
    const handoffId = `init-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üöÄ [${handoffId}] SESSION INIT: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      const { session_mode } = parameters;
      
      if (!['daily_journal', 'memory_creation', 'memory_browsing', 'general_chat'].includes(session_mode)) {
        logHandoff('‚ùå VALIDATION FAILED', { invalidMode: session_mode });
        return 'Invalid session mode. Please choose: daily_journal, memory_creation, memory_browsing, or general_chat.';
      }

      logHandoff('2Ô∏è‚É£ VALIDATED', { mode: session_mode });

      // Update conversation state with selected mode
      setConversationState(prev => ({
        ...prev,
        sessionMode: session_mode,
        conversationPhase: 'active_conversation'
      }));

      logHandoff('3Ô∏è‚É£ STATE UPDATED', { newMode: session_mode, phase: 'active_conversation' });

      // Generate mode-specific follow-up response
      const responses = {
        daily_journal: "Perfect! I'm here to help you create your daily journal entry. Let's start with what happened today - what stands out to you from your day? It could be something big or small, meaningful or routine. I'll help you capture it as a personal reflection.",
        memory_creation: "Wonderful! I'm ready to help you preserve a meaningful memory. Think of a specific moment, experience, or story from your life that you'd like to save. It could be from any time period - recent or long ago. What memory would you like to share with me?",
        memory_browsing: "Excellent! I'll help you explore and work with your existing memories. You can ask me to find specific memories, browse by topics or time periods, and even add to or modify memories you've already saved. What would you like to do? Search for something specific, or shall I show you some recent memories?",
        general_chat: "Great choice! I'm here for an open conversation about your life experiences. We can explore memories, talk about current reflections, or discuss whatever feels meaningful to you right now. What's on your mind today?"
      };

      const response = responses[session_mode];
      
      logHandoff('‚úÖ HANDOFF COMPLETE', { 
        status: 'success',
        mode: session_mode,
        agentResponse: `Mode set to ${session_mode}. Ready for specialized conversation.`
      });

      return response;
    } catch (error) {
      logHandoff('‚ùå HANDOFF FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return 'Error initializing session. Please try again or proceed with general conversation.';
    }
  }, []);

  // Memory editing tool for verbal modifications through Solin
  const editMemoryTool = useCallback(async (parameters: {
    memory_id: string;
    edit_type: 'modify' | 'add_to' | 'replace_section';
    new_content: string;
    section_description?: string; // For replace_section: describes what part to replace
  }) => {
    const handoffId = `edit-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`‚úèÔ∏è [${handoffId}] MEMORY EDIT: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      const { memory_id, edit_type, new_content, section_description } = parameters;
      
      if (!memory_id?.trim() || !edit_type || !new_content?.trim()) {
        logHandoff('‚ùå VALIDATION FAILED', { 
          hasMemoryId: !!memory_id, 
          hasEditType: !!edit_type, 
          hasContent: !!new_content 
        });
        return 'Missing required information. Please provide memory ID, edit type, and new content.';
      }

      if (!effectiveUser?.id) {
        logHandoff('‚ùå NO USER ID', { message: 'User must be logged in to edit memories' });
        return 'You must be logged in to edit memories. Please sign in and try again.';
      }

      const userId = effectiveUser.id;
      
      logHandoff('2Ô∏è‚É£ FETCHING EXISTING MEMORY', { userId, memoryId: memory_id });

      // First, get the existing memory (handle chunked memories)
      const { data: memoryChunks, error: fetchError } = await supabase
        .from('memories')
        .select('*')
        .eq('user_id', userId)
        .or(`id.eq.${memory_id},memory_group_id.eq.(SELECT memory_group_id FROM memories WHERE id = '${memory_id}' AND user_id = '${userId}')`)
        .order('chunk_sequence');

      if (fetchError) {
        logHandoff('‚ùå FETCH ERROR', { error: fetchError.message });
        return `Error retrieving memory: ${fetchError.message}`;
      }

      if (!memoryChunks || memoryChunks.length === 0) {
        logHandoff('‚ùå MEMORY NOT FOUND', { memoryId: memory_id });
        return 'Memory not found or you do not have permission to edit it.';
      }

      // Reconstruct full memory content if chunked
      const { reconstructMemoryFromChunks } = await import('@/utils/memoryChunking');
      const originalContent = memoryChunks.length > 1 
        ? reconstructMemoryFromChunks(memoryChunks.map(chunk => ({
            content: chunk.text,
            chunkSequence: chunk.chunk_sequence || 1,
            totalChunks: chunk.total_chunks || 1,
            memoryGroupId: chunk.memory_group_id
          })))
        : memoryChunks[0].text;

      const originalMemory = memoryChunks[0];
      
      logHandoff('3Ô∏è‚É£ PROCESSING EDIT', { 
        editType: edit_type, 
        originalLength: originalContent.length,
        newContentLength: new_content.length 
      });

      let updatedContent = '';

      switch (edit_type) {
        case 'add_to':
          // Append new content to existing memory
          updatedContent = originalContent + '\n\n--- Added ---\n\n' + new_content.trim();
          break;
        
        case 'replace_section':
          // Replace a specific section (simple approach - could be enhanced with AI)
          if (section_description) {
            // For now, simple replacement - could use AI to identify sections later
            updatedContent = originalContent + '\n\n--- Updated Section ---\n\n' + new_content.trim();
          } else {
            updatedContent = new_content.trim(); // Replace entire content if no section specified
          }
          break;
        
        case 'modify':
        default:
          // Complete replacement of memory content
          updatedContent = new_content.trim();
          break;
      }

      logHandoff('4Ô∏è‚É£ CHUNKING UPDATED CONTENT', { 
        editType: edit_type,
        finalLength: updatedContent.length 
      });

      // Re-chunk the updated content
      const { chunkMemoryContent } = await import('@/utils/memoryChunking');
      const newChunks = chunkMemoryContent(updatedContent, originalMemory.memory_group_id);

      // Delete old chunks and insert new ones (atomic operation)
      logHandoff('5Ô∏è‚É£ UPDATING DATABASE', { 
        oldChunks: memoryChunks.length, 
        newChunks: newChunks.length 
      });

      // Start transaction-like operations
      const { error: deleteError } = await supabase
        .from('memories')
        .delete()
        .eq('memory_group_id', originalMemory.memory_group_id)
        .eq('user_id', userId);

      if (deleteError) {
        logHandoff('‚ùå DELETE ERROR', { error: deleteError.message });
        return `Error updating memory: ${deleteError.message}`;
      }

      // Insert updated chunks
      const memoryInserts = newChunks.map(chunk => ({
        user_id: userId,
        title: newChunks.length > 1 ? `${originalMemory.title} (Part ${chunk.chunkSequence}/${chunk.totalChunks})` : originalMemory.title,
        text: chunk.content,
        tags: originalMemory.tags,
        memory_date: originalMemory.memory_date,
        memory_location: originalMemory.memory_location,
        memory_group_id: chunk.memoryGroupId,
        chunk_sequence: chunk.chunkSequence,
        total_chunks: chunk.totalChunks,
        image_urls: originalMemory.image_urls,
      }));

      const { data: updatedMemory, error: insertError } = await supabase
        .from('memories')
        .insert(memoryInserts)
        .select();

      if (insertError) {
        logHandoff('‚ùå INSERT ERROR', { error: insertError.message });
        return `Error saving updated memory: ${insertError.message}`;
      }

      logHandoff('6Ô∏è‚É£ UPDATE COMPLETE', { 
        memoryTitle: originalMemory.title,
        chunksCreated: updatedMemory.length 
      });

      // Update conversation state to track the active memory
      setConversationState(prev => ({
        ...prev,
        activeMemoryId: memory_id
      }));

      toast({
        title: 'Memory Updated',
        description: `"${originalMemory.title}" has been successfully modified.`,
        duration: 5000,
      });

      logHandoff('‚úÖ EDIT COMPLETE', {
        status: 'success',
        editType: edit_type,
        memoryTitle: originalMemory.title
      });

      const editTypeDescriptions = {
        add_to: 'added new content to',
        modify: 'updated',
        replace_section: 'modified a section of'
      };

      return `I've successfully ${editTypeDescriptions[edit_type]} your memory "${originalMemory.title}". The changes have been saved. Would you like to make any other modifications or work with a different memory?`;

    } catch (error) {
      logHandoff('‚ùå EDIT FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return `Failed to edit memory: ${error instanceof Error ? error.message : 'Unknown error'}. Please try again.`;
    }
  }, [effectiveUser?.id, toast, supabase]);

  // Enhanced memory retrieval tool with conversational presentation
  const browseMemoriesTool = useCallback(async (parameters: {
    search_query?: string;
    time_period?: 'recent' | 'this_year' | 'last_year' | 'older';
    limit?: number;
    action?: 'search' | 'browse_recent' | 'browse_by_topic';
  }) => {
    const handoffId = `browse-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üîç [${handoffId}] MEMORY BROWSE: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      if (!effectiveUser?.id) {
        return 'You must be logged in to browse your memories.';
      }

      const { search_query, time_period, limit = 8, action = 'browse_recent' } = parameters;
      const userId = effectiveUser.id;

      let query = supabase
        .from('memories')
        .select('id, title, text, memory_date, memory_location, created_at, chunk_sequence, memory_group_id')
        .eq('user_id', userId);

      // Apply time period filter
      if (time_period) {
        const now = new Date();
        let startDate;
        
        switch (time_period) {
          case 'recent':
            startDate = new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000); // Last 30 days
            break;
          case 'this_year':
            startDate = new Date(now.getFullYear(), 0, 1);
            break;
          case 'last_year':
            startDate = new Date(now.getFullYear() - 1, 0, 1);
            query = query.lt('created_at', new Date(now.getFullYear(), 0, 1).toISOString());
            break;
          case 'older':
            startDate = new Date(now.getFullYear() - 2, 0, 1);
            query = query.lt('created_at', startDate.toISOString());
            break;
        }
        
        if (time_period !== 'older' && time_period !== 'last_year') {
          query = query.gte('created_at', startDate!.toISOString());
        }
      }

      // Apply search filter
      if (search_query?.trim()) {
        const escaped = search_query.trim().replace(/%/g, '%25').replace(/\\/g, '\\\\');
        query = query.or(`title.ilike.%${escaped}%,text.ilike.%${escaped}%`);
      }

      // Only get first chunk of each memory group to avoid duplicates
      query = query.eq('chunk_sequence', 1);
      query = query.order('created_at', { ascending: false }).limit(limit);

      const { data: memories, error } = await query;

      logHandoff('2Ô∏è‚É£ QUERY EXECUTED', { 
        memoriesFound: memories?.length || 0, 
        searchQuery: search_query,
        timePeriod: time_period 
      });

      if (error) {
        logHandoff('‚ùå QUERY ERROR', { error: error.message });
        return `Error retrieving memories: ${error.message}`;
      }

      if (!memories || memories.length === 0) {
        const noResultsMessages = {
          search: search_query ? `No memories found matching "${search_query}".` : 'No memories found.',
          browse_recent: 'You don\'t have any recent memories saved yet.',
          browse_by_topic: 'No memories found for that topic.'
        };
        return noResultsMessages[action] + ' Would you like to create a new memory or try a different search?';
      }

      // Format results conversationally
      let response = '';
      
      if (search_query) {
        response += `I found ${memories.length} memor${memories.length === 1 ? 'y' : 'ies'} matching "${search_query}":\n\n`;
      } else if (time_period) {
        const periodNames = {
          recent: 'recent memories',
          this_year: 'memories from this year',
          last_year: 'memories from last year',
          older: 'older memories'
        };
        response += `Here are your ${periodNames[time_period]}:\n\n`;
      } else {
        response += `Here are your recent memories:\n\n`;
      }

      memories.forEach((memory, index) => {
        const date = memory.memory_date 
          ? new Date(memory.memory_date).toLocaleDateString()
          : new Date(memory.created_at).toLocaleDateString();
        
        const location = memory.memory_location ? ` in ${memory.memory_location}` : '';
        const preview = memory.text.length > 100 
          ? memory.text.substring(0, 100) + '...'
          : memory.text;
        
        response += `${index + 1}. **${memory.title}** (${date}${location})\n`;
        response += `   ${preview}\n`;
        response += `   [Memory ID: ${memory.id}]\n\n`;
      });

      response += `\nTo work with any memory, just tell me the number or title, and I can:\n`;
      response += `‚Ä¢ Read the full memory to you\n`;
      response += `‚Ä¢ Add new details to it\n`;
      response += `‚Ä¢ Modify or update parts of it\n`;
      response += `‚Ä¢ Help you expand on the story\n\n`;
      response += `What would you like to do?`;

      logHandoff('‚úÖ BROWSE COMPLETE', { 
        memoriesReturned: memories.length,
        responseLength: response.length 
      });

      return response;

    } catch (error) {
      logHandoff('‚ùå BROWSE FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return `Error browsing memories: ${error instanceof Error ? error.message : 'Unknown error'}. Please try again.`;
    }
  }, [effectiveUser?.id, supabase]);

  // Voice search tool for finding and playing back conversations
  const voiceSearchTool = useCallback(async (parameters: {
    search_query: string;
    search_type?: 'transcript' | 'summary' | 'topics';
    limit?: number;
  }) => {
    const handoffId = `voice-search-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üéµ [${handoffId}] VOICE SEARCH: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      if (!effectiveUser?.id) {
        return 'You must be logged in to search your voice recordings.';
      }

      const { search_query, limit = 5 } = parameters;
      
      if (!search_query?.trim()) {
        return 'Please provide a search term to find your voice recordings.';
      }

      const userId = effectiveUser.id;
      
      logHandoff('2Ô∏è‚É£ SEARCHING RECORDINGS', { query: search_query, limit });

      // Search voice recordings
      const recordings = await voiceRecordingService.searchRecordings(userId, search_query.trim(), limit);

      if (recordings.length === 0) {
        logHandoff('3Ô∏è‚É£ NO RESULTS', { query: search_query });
        return `I didn't find any voice recordings matching "${search_query}". Try different keywords or create some memories first to build up your voice history.`;
      }

      logHandoff('4Ô∏è‚É£ FORMATTING RESULTS', { recordingsFound: recordings.length });

      // Format results conversationally
      let response = `I found ${recordings.length} voice recording${recordings.length === 1 ? '' : 's'} matching "${search_query}":\n\n`;

      recordings.forEach((recording, index) => {
        const date = new Date(recording.created_at).toLocaleDateString();
        const duration = Math.round(recording.duration_seconds);
        const minutes = Math.floor(duration / 60);
        const seconds = duration % 60;
        const durationText = minutes > 0 ? `${minutes}m ${seconds}s` : `${seconds}s`;
        
        const sessionModeText = recording.session_mode || 'conversation';
        const memoryCount = recording.memory_ids?.length || 0;
        const memoryText = memoryCount > 0 ? ` (${memoryCount} memories created)` : '';
        
        response += `${index + 1}. **${sessionModeText.replace('_', ' ')}** - ${date} (${durationText}${memoryText})\n`;
        response += `   ${recording.conversation_summary || 'Conversation recording'}\n`;
        
        if (recording.topics && recording.topics.length > 0) {
          response += `   Topics: ${recording.topics.slice(0, 3).join(', ')}\n`;
        }
        
        response += `   [Recording ID: ${recording.id}]\n\n`;
      });

      response += `To listen to any recording, just tell me the number or say "play recording [number]". I can also:\n`;
      response += `‚Ä¢ Read you the transcript of what was said\n`;
      response += `‚Ä¢ Find specific moments within a recording\n`;
      response += `‚Ä¢ Show you memories created during that conversation\n\n`;
      response += `What would you like to do with these recordings?`;

      logHandoff('‚úÖ SEARCH COMPLETE', { 
        recordingsReturned: recordings.length,
        responseLength: response.length 
      });

      return response;

    } catch (error) {
      logHandoff('‚ùå SEARCH FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return `Error searching voice recordings: ${error instanceof Error ? error.message : 'Unknown error'}. Please try again.`;
    }
  }, [effectiveUser?.id]);

  // Play voice recording tool
  const playVoiceRecordingTool = useCallback(async (parameters: {
    recording_id?: string;
    recording_number?: number;
    action?: 'play' | 'transcript' | 'summary';
  }) => {
    const handoffId = `voice-play-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üéµ [${handoffId}] VOICE PLAY: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      if (!effectiveUser?.id) {
        return 'You must be logged in to access your voice recordings.';
      }

      const { recording_id, recording_number, action = 'play' } = parameters;
      
      if (!recording_id && !recording_number) {
        return 'Please specify which recording you want to access by ID or number from the search results.';
      }

      const userId = effectiveUser.id;
      
      logHandoff('2Ô∏è‚É£ FETCHING RECORDING', { recordingId: recording_id, recordingNumber: recording_number });

      // Get recording details
      let query = supabase
        .from('voice_recordings')
        .select('*')
        .eq('user_id', userId);

      if (recording_id) {
        query = query.eq('id', recording_id);
      }
      
      const { data: recordings, error } = await query
        .order('created_at', { ascending: false })
        .limit(recording_number ? recording_number : 1);

      if (error) {
        logHandoff('‚ùå FETCH ERROR', { error: error.message });
        return `Error retrieving recording: ${error.message}`;
      }

      let recording;
      if (recording_number && recordings) {
        recording = recordings[recording_number - 1]; // Convert to 0-based index
      } else if (recordings && recordings.length > 0) {
        recording = recordings[0];
      }

      if (!recording) {
        logHandoff('‚ùå RECORDING NOT FOUND', { recordingId: recording_id, recordingNumber: recording_number });
        return 'Recording not found. Please check the ID or number and try again.';
      }

      logHandoff('3Ô∏è‚É£ PROCESSING REQUEST', { 
        action, 
        recordingId: recording.id,
        duration: recording.duration_seconds 
      });

      if (action === 'transcript') {
        if (!recording.transcript_text) {
          return 'No transcript is available for this recording.';
        }
        
        const date = new Date(recording.created_at).toLocaleDateString();
        const duration = Math.round(recording.duration_seconds);
        const durationText = duration > 60 ? `${Math.floor(duration/60)}m ${duration%60}s` : `${duration}s`;
        
        return `Here's the transcript from your ${recording.session_mode?.replace('_', ' ')} session on ${date} (${durationText}):\n\n"${recording.transcript_text}"\n\nWould you like me to play the audio, or is there anything specific you want to know about this conversation?`;
      }

      if (action === 'summary') {
        const date = new Date(recording.created_at).toLocaleDateString();
        const memoryCount = recording.memory_ids?.length || 0;
        const topicsText = recording.topics?.length > 0 ? `\nTopics discussed: ${recording.topics.join(', ')}` : '';
        
        return `Summary of your ${recording.session_mode?.replace('_', ' ')} session from ${date}:\n\n${recording.conversation_summary || 'No summary available'}${topicsText}\n\n${memoryCount > 0 ? `${memoryCount} memories were created during this conversation.\n\n` : ''}Would you like to hear the full recording or see the transcript?`;
      }

      // Default action: play
      logHandoff('4Ô∏è‚É£ GENERATING PLAY URL', { storagePath: recording.storage_path });
      
      try {
        const audioUrl = await voiceRecordingService.getAudioUrl(recording.storage_path);
        
        const date = new Date(recording.created_at).toLocaleDateString();
        const duration = Math.round(recording.duration_seconds);
        const durationText = duration > 60 ? `${Math.floor(duration/60)}m ${duration%60}s` : `${duration}s`;
        
        // Note: In a real implementation, you'd need a way to trigger audio playback in the browser
        // For now, we'll provide instructions to the user
        logHandoff('‚úÖ PLAY REQUEST COMPLETE', { audioUrl: 'generated', duration: recording.duration_seconds });
        
        return `I've prepared your ${recording.session_mode?.replace('_', ' ')} recording from ${date} (${durationText}) for playback. Unfortunately, I can't directly play audio through voice conversation yet, but I can:\n\n1. Read you the transcript of what was said\n2. Give you a summary of the conversation\n3. Show you any memories that were created\n\nWhich would you prefer? Or would you like to search for a different recording?`;
        
      } catch (audioError) {
        logHandoff('‚ùå AUDIO URL ERROR', { error: audioError });
        return 'I found the recording but had trouble preparing it for playback. Would you like me to read the transcript instead?';
      }

    } catch (error) {
      logHandoff('‚ùå PLAY FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return `Error accessing voice recording: ${error instanceof Error ? error.message : 'Unknown error'}. Please try again.`;
    }
  }, [effectiveUser?.id, supabase]);

  // Enhanced conversation suggestions tool that considers session mode
  const getConversationSuggestionsTool = useCallback(async (parameters: {
    type: 'starter' | 'followup' | 'reflection';
    context?: string;
    recent_memory_id?: string;
  }) => {
    const handoffId = `suggestions-${Date.now()}`;
    const logHandoff = (stage: string, data?: any) => {
      const timestamp = new Date().toISOString();
      console.log(`üí≠ [${handoffId}] SUGGESTIONS: ${stage} @ ${timestamp}`, data || '');
    };

    try {
      logHandoff('1Ô∏è‚É£ RECEIVED', { source: 'ElevenLabs voice agent', parameters });

      const { type } = parameters;
      let suggestions: string[] = [];

      // For greeting phase, provide mode selection questions
      if (conversationState.conversationPhase === 'greeting' || conversationState.sessionMode === 'unset') {
        logHandoff('2Ô∏è‚É£ GREETING PHASE', { phase: conversationState.conversationPhase });
        
        const greetingOptions = [
          "Hi! I'm Solin, your memory companion. Would you like to create a daily journal entry, preserve a new memory, browse and edit existing memories, or just have an open conversation?",
          "Hello! I can help you in a few ways today: daily reflection, capture new memories, explore and modify existing memories, or general conversation. What interests you?",
          "Welcome! I'm here to help with your life stories. Are you looking to journal about today, share a new memory, work with memories you've already saved, or have a general chat?"
        ];

        // Return one random greeting option
        suggestions = [greetingOptions[Math.floor(Math.random() * greetingOptions.length)]];
        
        logHandoff('‚úÖ GREETING SUGGESTIONS', { count: suggestions.length });
        return suggestions.join('\n\n');
      }

      // Generate suggestions based on session mode and conversation phase
      const { sessionMode } = conversationState;
      
      if (sessionMode === 'daily_journal') {
        if (type === 'starter') {
          suggestions = [
            "What was the highlight of your day today?",
            "How are you feeling as you reflect on today?",
            "What's one thing that happened today that you want to remember?",
            "Tell me about a moment from today that stood out to you."
          ];
        } else if (type === 'followup') {
          suggestions = [
            "How did that make you feel in the moment?",
            "What did you learn about yourself from that experience?",
            "Is this something you'd like to do more often?",
            "What would you tell someone else who experienced something similar?"
          ];
        }
      } else if (sessionMode === 'memory_creation') {
        if (type === 'starter') {
          suggestions = [
            "What's a memory that always brings a smile to your face?",
            "Tell me about a moment that changed your perspective on something.",
            "What's a story from your past that you'd want future generations to know?",
            "Share a memory of someone who made a significant impact on your life."
          ];
        } else if (type === 'followup') {
          suggestions = [
            "What details about that day do you remember most vividly?",
            "Who else was there, and what were they like?",
            "How did that experience shape who you are today?",
            "What emotions come up when you think about that time?"
          ];
        }
      } else if (sessionMode === 'memory_browsing') {
        if (type === 'starter') {
          suggestions = [
            "Would you like me to show you your recent memories, or are you looking for something specific?",
            "I can help you find memories by topic, time period, or search terms. What are you interested in exploring?",
            "What memories would you like to revisit today? I can browse by theme, date, or help you search for specific experiences.",
            "Are you looking to find a particular memory, or would you like me to show you what you've saved recently?"
          ];
        } else if (type === 'followup') {
          suggestions = [
            "Would you like me to read the full memory to you?",
            "Is there anything you'd like to add to this memory?",
            "Would you like to modify or update any part of this memory?",
            "Does this memory remind you of other related experiences you'd like to explore?"
          ];
        }
      } else {
        // General chat mode - use existing intelligent prompting
        if (!effectiveUser?.id) {
          suggestions = [
            "What's something meaningful that's happened in your life recently?",
            "Tell me about a person who has influenced you.",
            "What's a decision you've made that you're proud of?"
          ];
        } else {
          // Use existing intelligent prompting system
          const memoryProfile = conversationState.userMemoryProfile;
          if (memoryProfile && type === 'starter') {
            suggestions = intelligentPrompting.generateConversationStarters(memoryProfile);
          } else if (type === 'reflection') {
            const lastTopic = conversationState.recentTopics[0];
            suggestions = intelligentPrompting.generateReflectionPrompts(memoryProfile, lastTopic);
          }
        }
      }

      logHandoff('3Ô∏è‚É£ GENERATED', { 
        sessionMode, 
        type, 
        suggestionCount: suggestions.length,
        phase: conversationState.conversationPhase 
      });

      // Fallback suggestions if none generated
      if (suggestions.length === 0) {
        suggestions = [
          "What's on your mind right now?",
          "Tell me about something that's been important to you lately.",
          "What would you like to explore or remember today?"
        ];
        logHandoff('4Ô∏è‚É£ FALLBACK USED', { count: suggestions.length });
      }

      logHandoff('‚úÖ SUGGESTIONS COMPLETE', { finalCount: suggestions.length });

      // Return top 3 suggestions, separated by newlines
      return suggestions.slice(0, 3).join('\n\n');
    } catch (error) {
      logHandoff('‚ùå SUGGESTIONS FAILED', { error: error instanceof Error ? error.message : 'Unknown error' });
      return "What would you like to talk about today?";
    }
  }, [effectiveUser, conversationState, intelligentPrompting]);

  const conversationOptionsRef = useRef({
    clientTools: { 
      save_memory: saveMemoryTool,
      save_biography_topic: saveBiographyTopicTool,
      retrieve_memory: retrieveMemoryTool,
      get_memory_details: getMemoryDetailsTool,
      browse_memories: browseMemoriesTool,
      edit_memory: editMemoryTool,
      voice_search: voiceSearchTool,
      play_voice_recording: playVoiceRecordingTool,
      get_conversation_suggestions: getConversationSuggestionsTool,
      initialize_session: initializeSessionTool,
      close_conversation: closeConversationTool,
      edit_biography: editBiographyTool
    },
    onConnect: onConnectCb,
    onDisconnect: onDisconnectCb,
    onError: onErrorCb,
  onMessage: (message: unknown) => {
      console.log('üó£Ô∏è ElevenLabs message:', message);
      
      // Enhanced debugging for transcript capture
      if (typeof message === 'object' && message !== null) {
        const msg = message as any;
        
        // Check for audio data in the message
        if (msg.audio || msg.audio_data || msg.audioData || msg.delta || msg.chunk) {
          console.log('üéµ AUDIO DATA DETECTED in message:', {
            type: msg.type,
            hasAudio: !!msg.audio,
            hasAudioData: !!msg.audioData,
            hasDelta: !!msg.delta,
            hasChunk: !!msg.chunk,
            keys: Object.keys(msg)
          });
          
          // Try to capture agent audio if recording
          if (isRecording && recordingMode === 'enhanced') {
            const audioData = msg.audio || msg.audio_data || msg.audioData || msg.delta || msg.chunk;
            if (audioData && typeof audioData === 'string') {
              console.log('üéôÔ∏è Capturing agent audio chunk from message...');
              enhancedConversationRecordingService.captureAgentAudioChunk(audioData);
            }
          }
        }
        
        console.log('üìù Message analysis:', {
          type: msg.type,
          source: msg.source,
          hasMessage: !!msg.message,
          hasDelta: !!msg.delta,
          hasAudio: !!(msg.audio || msg.audio_data || msg.audioData),
          isRecording,
          messageKeys: Object.keys(msg),
          fullMessage: msg
        });
        
        // End-of-conversation phrase detection (both user and AI)
        const extractText = () => msg.message || msg.delta || msg.transcript || '';
        const text = String(extractText()).toLowerCase();
        const endPhrases = ['bye', 'goodbye', 'end conversation', 'end session', 'stop talking', 'that\'s all'];
        if (text) {
          const hasEnd = endPhrases.some(p => text.includes(p));
          if (hasEnd) {
            const who = msg.source || msg.type || 'unknown';
            console.log('üîö Detected end phrase from', who, '‚Üí scheduling end');
            // Use minimal delay - scheduleEnd will wait for Solin to finish speaking
            const delay = (msg.source === 'ai' || msg.type?.includes('response')) ? 500 : 500;
            scheduleEnd(delay, `phrase_${who}`);
          }
        }
        
        // Handle different message types for transcript capture
        let transcriptText = '';
        let speaker: 'user' | 'ai' | null = null;
        
        if (msg.type === 'response.audio_transcript.delta' && msg.delta) {
          transcriptText = msg.delta;
          speaker = 'ai';
          console.log('üìù AI transcript delta captured:', transcriptText);
          
          setConversationMessages(prev => {
            const last = prev[prev.length - 1];
            if (last && last.role === 'ai') {
              return [...prev.slice(0, -1), { role: 'ai', text: last.text + msg.delta }];
            }
            return [...prev, { role: 'ai', text: msg.delta }];
          });
        } else if (msg.type === 'response.audio_transcript.done' && msg.transcript) {
          transcriptText = msg.transcript;
          speaker = 'ai';
          console.log('üìù AI transcript complete captured:', transcriptText);
        } else if (msg.source === 'user' && msg.message) {
          transcriptText = msg.message;
          speaker = 'user';
          console.log('üìù User message captured:', transcriptText);
          
          setConversationMessages(prev => [...prev, { role: 'user', text: msg.message }]);
          
          // Extract topics from user messages for smarter context
          const topics = msg.message.toLowerCase().match(/\b(family|childhood|school|work|travel|memory|remember|story|time|years?|ago)\b/g) || [];
          if (topics.length > 0) {
            setConversationState(prev => ({
              ...prev,
              recentTopics: [...new Set([...topics, ...prev.recentTopics])].slice(0, 10)
            }));
          }
        } else if (msg.source === 'ai' && msg.message) {
          transcriptText = msg.message;
          speaker = 'ai';
          console.log('üìù AI message captured:', transcriptText);
          
          setConversationMessages(prev => [...prev, { role: 'ai', text: msg.message }]);
        } else if (msg.type === 'user_transcript' && msg.transcript) {
          transcriptText = msg.transcript;
          speaker = 'user';
          console.log('üìù User transcript captured:', transcriptText);
        }
        
        // Add to conversation recording transcript if we have valid content
        if (transcriptText && speaker && isRecording) {
          console.log('üìù Adding to conversation transcript:', { speaker, text: transcriptText.substring(0, 50) + '...', mode: recordingMode });
          
          if (recordingMode === 'enhanced') {
            enhancedConversationRecordingService.addEnhancedTranscriptEntry(speaker, transcriptText, msg.confidence);
          } else {
            conversationRecordingService.addTranscriptEntry(speaker, transcriptText);
          }
        } else if (isRecording) {
          console.log('üìù Transcript not added - missing data:', { hasText: !!transcriptText, hasSpeaker: !!speaker, isRecording, mode: recordingMode });
        }
      }
    },
  });

  const conversation = useConversation(conversationOptionsRef.current);

  // Removed agentId fallback; we only use signedUrl sessions to match SDK types.


  useEffect(() => {
    console.log('üõ∞Ô∏è Conversation status:', conversation.status, 'speaking:', conversation.isSpeaking);
  }, [conversation.status, conversation.isSpeaking]);

  // ===== DEBUG: Expose voice recording test functions globally =====
  useEffect(() => {
    (window as any).testGuestRecording = testGuestRecording;
    (window as any).testAuthenticatedRecording = testAuthenticatedRecording;
    (window as any).checkDatabaseRecordings = checkDatabaseRecordings;
    (window as any).checkGuestRecordings = checkGuestRecordings;
    (window as any).voiceRecordingService = voiceRecordingService;
    console.log('üîß DEBUG: Voice recording test functions exposed to window object');
  }, []);

  const startConversation = useCallback(async () => {
    console.log('üöÄ START CONVERSATION: Function called');

    // Prevent duplicate starts
    if (isConnecting || conversation.status === 'connected') {
      console.log('‚è≠Ô∏è Already connecting/connected. Skipping start.');
      return;
    }

    // Cancel any pending reconnect timers
    if (reconnectTimeoutRef.current) {
      clearTimeout(reconnectTimeoutRef.current);
      reconnectTimeoutRef.current = null;
    }
    
    // Define sessionHandoffId at function scope so it's available in catch block
    const sessionHandoffId = `session-${Date.now()}`;
    
    try {
      console.log('üöÄ START CONVERSATION: Setting isConnecting to true');
      setIsConnecting(true);
      
      // Check authentication status first
      console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: üîç CHECKING AUTH STATUS`);
      
      console.log('üöÄ START CONVERSATION: About to call supabase.auth.getSession()');
      const { data: { session }, error: sessionError } = await supabase.auth.getSession();
      console.log('üöÄ START CONVERSATION: Got session response:', { session: !!session, error: !!sessionError });
      
      if (sessionError) {
        console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: ‚ö†Ô∏è SESSION CHECK ERROR:`, sessionError);
      }
      
      const isAuthenticated = !!(session?.user);
      console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: üîê AUTH STATUS:`, {
        hasSession: !!session,
        hasUser: !!session?.user,
        userEmail: session?.user?.email || 'none',
        isAuthenticated,
        hasEffectiveUser: !!effectiveUser
      });
      
      // Require real authentication for voice agent
      const finalUserId = session?.user?.id;
      
      if (!finalUserId) {
        console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: ‚ùå AUTH REQUIRED`);
        throw new Error('Authentication system not available. Please refresh and try again.');
      }
      
      // Store user ID in ref for voice recording callback
      authenticatedUserIdRef.current = finalUserId;
      
      console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: üîê USING USER:`, {
        isAuthenticated,
        userId: finalUserId
      });
      
      // Check microphone permissions
      console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: üé§ REQUESTING MIC ACCESS`);
      await navigator.mediaDevices.getUserMedia({ audio: true });
      console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: ‚úÖ MIC ACCESS GRANTED`);

      // Proactively unlock audio on mobile/desktop to avoid autoplay policies blocking TTS
      try {
        console.log(`üîå [${sessionHandoffId}] CONNECTION HANDOFF: üéµ UNLOCKING AUDIO CONTEXT`);
        const AudioCtx = (window as any).AudioContext || (window as any).webkitAudioContext;
        if (AudioCtx) {
          const ctx = new AudioCtx();
          console.log(`üîå [${sessionHandoffId}] AudioContext state before resume:`, ctx.state);
          
          if (ctx.state === 'suspended') {
            await ctx.resume();
            console.log(`üîå [${sessionHandoffId}] AudioContext resumed, new state:`, ctx.state);
          }
          
          await new Promise(r => setTimeout(r, 50)); // Longer delay for mobile
          await ctx.close();
          console.log(`üîå [${sessionHandoffId}] AudioContext closed successfully`);
        }
      } catch (e) {
        console.warn(`üîå [${sessionHandoffId}] ‚ö†Ô∏è AudioContext unlock failed (safe to ignore):`, e);
      }

      let data, error;
      
      // Require real authentication for voice agent
      if (!session) {
        console.log(`üîå [${sessionHandoffId}] AUTH REQUIRED: No session`);
        console.log('üöÄ START CONVERSATION: EARLY RETURN - Authentication required');
        toast({
          title: "Authentication Required", 
          description: "Please sign in to use the voice agent.",
          variant: "destructive",
        });
        return;
      }
      
      console.log('üöÄ START CONVERSATION: Passed authentication check, proceeding...');

      // Get signed URL from elevenlabs-agent-token function
      console.log(`üîå [${sessionHandoffId}] EDGE FUNCTION HANDOFF: ‚û°Ô∏è CALLING elevenlabs-agent-token`);
      
      const response = await supabase.functions.invoke('elevenlabs-agent-token', {
        body: { 
          agentId: 'agent_3201k6n4rrz8e2wrkf9tv372y0w4'
        }
      });
      
      console.log(`üîå [${sessionHandoffId}] EDGE FUNCTION HANDOFF: üì¶ RAW RESPONSE:`, response);
      
      data = response.data;
      error = response.error;
      
      console.log(`üîå [${sessionHandoffId}] EDGE FUNCTION HANDOFF: üëÄ RESPONSE RECEIVED:`, {
        hasData: !!data,
        hasError: !!error,
        dataContent: data,
        errorContent: error,
        errorType: error?.message ? 'message' : error?.code ? 'code' : 'none',
        errorDetails: error?.message || error?.code || 'none'
      });

      if (error) {
        console.error(`üîå [${sessionHandoffId}] EDGE FUNCTION HANDOFF: ‚ùå FAILED - Edge function error:`, error);
        console.log(`üöÄ EXPLICIT ERROR CHECK: Error detected, about to throw`);
        
        // This throw should be caught by the outer catch block
        
        // Check if it's an auth error, network error, or function error
        if (error.message?.includes('Unauthorized')) {
          throw new Error('Authentication failed - please check if you are logged in');
        } else if (error.message?.includes('network')) {
          throw new Error('Network error - please check your connection');
        } else if (error.message?.includes('ElevenLabs API key not configured')) {
          throw new Error('ElevenLabs API key is not configured. Please add ELEVENLABS_API_KEY to your Supabase project settings.');
        } else {
          throw new Error(`Edge function failed: ${error.message || 'Unknown error'}`);
        }
      }
      
      if (!data?.signed_url) {
        console.error(`üîå [${sessionHandoffId}] EDGE FUNCTION HANDOFF: ‚ùå INVALID RESPONSE - No signed URL:`, data);
        throw new Error('Failed to get signed URL from elevenlabs-agent-token function');
      }
      
      console.log(`üîå [${sessionHandoffId}] EDGE FUNCTION HANDOFF: ‚úÖ SUCCESS - Got signed URL`);

      console.log('Starting session with memory context...');
      
      // Use a cancellable timeout to avoid unhandled rejection after connect
      let timeoutId: number | undefined;
      const timeoutPromise = new Promise((_, reject) => {
        timeoutId = window.setTimeout(() => reject(new Error('Connection timed out')), 20000);
      });

      const startPromise = conversation.startSession({
        signedUrl: data.signed_url,
        overrides: {
          agent: {
            prompt: {
              prompt: data.personalizedPrompt || "You are Solin, a warm and empathetic AI biographer."
            },
            firstMessage: data.firstMessage || "Hello! How can I help you today?"
          }
        }
      });

      await Promise.race([startPromise, timeoutPromise]);
      if (timeoutId) clearTimeout(timeoutId);
      
      // Set volume after session starts
      console.log('‚úÖ Session started successfully, setting volume...');
      try { 
        await conversation.setVolume({ volume: 1 }); 
        console.log('‚úÖ Volume set to 1');
      } catch (e) { 
        console.warn('‚ö†Ô∏è setVolume failed (safe to ignore):', e);
      }
      
    } catch (error) {
      console.log('üöÄ CATCH BLOCK: Error caught in try-catch');
      const errorMsg = error instanceof Error ? error.message : 'Could not start';
      
      // Enhanced diagnostic logging
      console.error('‚ùå FULL ERROR DETAILS:', {
        error,
        message: errorMsg,
        stack: error instanceof Error ? error.stack : 'No stack trace',
        type: typeof error,
        sessionHandoffId
      });
      
      // Provide specific guidance based on error type
      let userMessage = errorMsg;
      let diagnosticHint = '';
      
      if (errorMsg.includes('Authentication failed') || errorMsg.includes('Unauthorized')) {
        userMessage = 'Authentication issue - please check your login status.';
        diagnosticHint = 'Check: User authentication, Supabase session, JWT token validity';
      } else if (errorMsg.includes('Network error') || errorMsg.includes('fetch')) {
        userMessage = 'Connection issue. Please check your internet and try again.';
        diagnosticHint = 'Check: Internet connection, Supabase availability, CORS settings';
      } else if (errorMsg.includes('Edge function failed') || errorMsg.includes('ElevenLabs')) {
        userMessage = 'Service temporarily unavailable. Please try again in a moment.';
        diagnosticHint = 'Check: ElevenLabs API key, Supabase Edge function, API rate limits';
      } else if (errorMsg.includes('Connection timed out')) {
        userMessage = 'Connection timed out. The service might be slow or unavailable.';
        diagnosticHint = 'Check: ElevenLabs service status, network latency, WebSocket connectivity';
      } else {
        userMessage = `Connection failed: ${errorMsg}`;
        diagnosticHint = 'Check console for detailed error information';
      }
      
      console.log(`üîç DIAGNOSTIC HINT: ${diagnosticHint}`);
      
      toast({
        title: "Failed to connect",
        description: userMessage,
        variant: "destructive",
      });
    } finally {
      console.log('üöÄ START CONVERSATION: Finally block - setting isConnecting to false');
      setIsConnecting(false);
    }
  }, [conversation, toast, agentInstructions]);

  // Keep a stable ref to startConversation so callbacks can call it without re-creating deps
  useEffect(() => {
    startConversationRef.current = startConversation;
    return () => { startConversationRef.current = undefined; };
  }, [startConversation]);

  const endConversation = useCallback(async () => {
    try {
      console.log('üëã Manual conversation end requested...');
      setIsEndingConversation(true);
      
      // Show immediate feedback
      const timeoutSeconds = Math.round(configurationService.getConversationEndTimeout() / 1000);
      toast({ 
        title: 'Ending conversation...', 
        description: `Solin will say goodbye and wrap up naturally. The session will end automatically when Solin finishes speaking (max ${timeoutSeconds}s).`,
        duration: 6000
      });
      
      // Set up timeout and speaking monitoring for graceful conversation end
      let hasEnded = false;
      const endTimeout = setTimeout(async () => {
        if (hasEnded) return;
        hasEnded = true;
        try {
          console.log('üõë Timeout reached (2 minutes) - forcefully ending ElevenLabs session...');
          
          // More aggressive session termination
          if (conversation.status === 'connected') {
            await conversation.endSession();
          }
          
          // Note: conversation will auto-disconnect when endSession completes
          
          // Stop voice recording if active
          if (isRecording && recordingSessionId) {
            try {
              console.log(`üõë Stopping ${recordingMode} voice recording due to conversation end...`);
              if (recordingMode === 'enhanced') {
                await enhancedConversationRecordingService.stopEnhancedRecording();
              } else {
                await conversationRecordingService.stopConversationRecording();
              }
              setIsRecording(false);
              setRecordingSessionId(null);
              console.log(`‚úÖ ${recordingMode} voice recording stopped and saved`);
            } catch (error) {
              console.error(`‚ö†Ô∏è Failed to stop ${recordingMode} voice recording:`, error);
            }
          }

          // AUTO-SAVE: Create incomplete memory if conversation had content but no memory was saved
          await autoSaveConversationContent();
          
          
          // Clear all conversation state
          setConversationMessages([]);
          setIsEndingConversation(false);
          
          console.log('‚úÖ Session ended successfully');
          
          // Navigate to timeline with memory highlighting if we saved a memory during this session
          if (lastSavedMemoryId) {
            console.log(`üéØ Redirecting to Timeline with memory highlight: ${lastSavedMemoryId}`);
            navigate(`/timeline?highlight=${lastSavedMemoryId}&new=true`);
            toast({ 
              title: 'Conversation ended', 
              description: 'Session saved. Your new memory is highlighted on the Timeline!' 
            });
          } else {
            // No memory saved during this session, just go to timeline
            navigate('/timeline');
            toast({ 
              title: 'Conversation ended', 
              description: 'Session saved. Check your Timeline for memories!' 
            });
          }
        } catch (endError) {
          console.error('Error in forced session end:', endError);
          setIsEndingConversation(false);
        }
      }, configurationService.getConversationEndTimeout()); // Use configurable timeout
      
      // Also monitor for when Solin finishes speaking naturally
      const checkSpeakingStatus = () => {
        if (hasEnded) return;
        
        // If Solin has stopped speaking, wait a bit longer then end gracefully
        if (!conversation.isSpeaking && conversation.status === 'connected') {
          console.log('üéØ Solin finished speaking - ending conversation gracefully...');
          
          // Wait configured grace period after Solin stops speaking to ensure natural completion
          setTimeout(() => {
            if (hasEnded) return;
            hasEnded = true;
            clearTimeout(endTimeout);
            
            // End the conversation naturally since Solin finished speaking
            console.log('‚úÖ Natural conversation end - Solin finished speaking');
            
            // Force end session
            if (conversation.status === 'connected') {
              conversation.endSession().catch(console.error);
            }
            
            // Stop voice recording if active
            if (isRecording && recordingSessionId) {
              if (recordingMode === 'enhanced') {
                enhancedConversationRecordingService.stopEnhancedRecording().catch(console.error);
              } else {
                conversationRecordingService.stopConversationRecording().catch(console.error);
              }
              setIsRecording(false);
              setRecordingSessionId(null);
            }

            // AUTO-SAVE: Create incomplete memory if needed
            autoSaveConversationContent().catch(console.error);
            
            // Clear state and navigate
            setConversationMessages([]);
            setIsEndingConversation(false);
            
            if (lastSavedMemoryId) {
              navigate(`/timeline?highlight=${lastSavedMemoryId}&new=true`);
              toast({ 
                title: 'Conversation ended naturally', 
                description: 'Session saved. Your new memory is highlighted on the Timeline!' 
              });
            } else {
              navigate('/timeline');
              toast({ 
                title: 'Conversation ended', 
                description: 'Session saved. Check your Timeline for memories!' 
              });
            }
          }, configurationService.getNaturalEndGracePeriod()); // Use configurable grace period
        } else {
          // Check again at configured interval
          setTimeout(checkSpeakingStatus, configurationService.getSpeakingCheckInterval());
        }
      };
      
      // Start monitoring Solin's speaking status
      setTimeout(checkSpeakingStatus, configurationService.getSpeakingCheckInterval()); // Start checking at configured interval
      
    } catch (error) {
      console.error('Error ending conversation:', error);
      setIsEndingConversation(false);
      
      // Fallback: direct session end if initial attempt fails
      try {
        await conversation.endSession();
        setConversationMessages([]);
        toast({ title: 'Conversation ended', description: 'Your session has ended' });
      } catch (fallbackError) {
        console.error('Fallback end session failed:', fallbackError);
        toast({ title: 'Session end error', description: 'Please refresh the page', variant: 'destructive' });
      }
    }
  }, [conversation, toast, navigate]);

  // Bind endConversation to a ref for scheduling from other callbacks
  useEffect(() => {
    endConversationRef.current = () => { endConversation().catch(console.error); };
    return () => { endConversationRef.current = null; };
  }, [endConversation]);

  // Auto-save conversation content as incomplete memory when conversation ends
  const autoSaveConversationContent = useCallback(async () => {
    try {
      // Only auto-save if no memory was explicitly saved during this conversation
      if (lastSavedMemoryId) {
        console.log('üìù Skipping auto-save - memory already saved:', lastSavedMemoryId);
        return;
      }

      // Check if we have meaningful conversation content
      if (!conversationMessages || conversationMessages.length < 2) {
        console.log('üìù Skipping auto-save - insufficient conversation content');
        return;
      }

      // Get user messages (not AI responses)
      const userMessages = conversationMessages
        .filter(msg => msg.role === 'user')
        .map(msg => msg.text)
        .join('\n\n');

      // Only save if user contributed meaningful content
      if (!userMessages || userMessages.trim().length < 10) {
        console.log('üìù Skipping auto-save - insufficient user content');
        return;
      }

      const userId = effectiveUser?.id;
      if (!userId) {
        console.log('üìù Skipping auto-save - no user ID');
        return;
      }

      console.log('üìù Auto-saving conversation content as incomplete memory...');

      // Create incomplete memory entry
      const memoryData = {
        user_id: userId,
        title: 'Incomplete Conversation Memory',
        text: `[Auto-saved conversation content]\n\n${userMessages}`,
        memory_date: null, // No date = incomplete
        memory_location: null, // No location = incomplete
        tags: ['auto-saved', 'incomplete'],
        chunk_sequence: 1,
        is_primary_chunk: true,
        source_type: 'conversation_auto_save'
      };

      const { data: memory, error } = await supabase
        .from('memories')
        .insert(memoryData)
        .select()
        .single();

      if (error) {
        console.error('‚ùå Auto-save failed:', error);
        return;
      }

      console.log('‚úÖ Auto-saved incomplete memory:', memory.id);
      
      // Update last saved memory ID so it appears in navigation
      setLastSavedMemoryId(memory.id);

      // Try to link to voice recording if we have one
      if (recordingSessionId) {
        try {
          await supabase
            .from('voice_recordings')
            .update({ memory_ids: [memory.id] })
            .eq('session_id', recordingSessionId);
          
          console.log('‚úÖ Linked auto-saved memory to voice recording');
        } catch (linkError) {
          console.warn('‚ö†Ô∏è Failed to link memory to recording:', linkError);
        }
      }

      // Show notification about auto-save
      toast({
        title: 'Conversation Auto-Saved',
        description: 'Your conversation has been saved as an incomplete memory. Complete it in the Archive to add it to your Timeline.',
        duration: 5000,
      });

    } catch (error) {
      console.error('‚ùå Auto-save conversation failed:', error);
    }
  }, [conversationMessages, lastSavedMemoryId, effectiveUser?.id, recordingSessionId, supabase, toast]);

  useEffect(() => {
    startConversationRef.current = startConversation;
    return () => { startConversationRef.current = undefined; };
  }, [startConversation]);

  // Check if user needs first conversation
  useEffect(() => {
    const checkFirstConversationStatus = async () => {
      if (!effectiveUser?.id) {
        setCheckingProfile(false);
        return;
      }

      try {
        console.log('üîç Checking first conversation status...');
        
        const needsFirstConv = await userProfileService.needsFirstConversation(effectiveUser.id);
        
        console.log(`üë§ User needs first conversation: ${needsFirstConv}`);
        setNeedsFirstConversation(needsFirstConv);
        
        if (needsFirstConv) {
          setShowFirstConversation(true);
        }
      } catch (error) {
        console.error('‚ùå Error checking first conversation status:', error);
        // Default to showing first conversation on error for safety
        setNeedsFirstConversation(true);
        setShowFirstConversation(true);
      } finally {
        setCheckingProfile(false);
      }
    };

    checkFirstConversationStatus();
  }, [effectiveUser?.id]);

  // Handle first conversation completion
  const handleFirstConversationComplete = useCallback(() => {
    console.log('‚úÖ First conversation completed');
    setNeedsFirstConversation(false);
    setShowFirstConversation(false);
    
    toast({
      title: 'Welcome to Solin!',
      description: 'Your profile has been created. Let\'s start capturing your memories!',
    });
  }, [toast]);

  const isConnected = conversation.status === 'connected';
  const isSpeaking = conversation.isSpeaking;

  const lastClickRef = useRef(0);
  const handleOrbPress = useCallback(async () => {
    const now = Date.now();

    if (isTogglingRef.current) {
      console.log('‚è≥ Toggle in progress, ignoring press');
      return;
    }

    if (now - lastClickRef.current < 700) {
      console.log('‚è±Ô∏è Ignored rapid orb tap');
      return;
    }

    // Orb now only STARTS the session. It will not end it.
    if (isConnected) {
      console.log('‚ÑπÔ∏è Orb press ignored while connected (use End button)');
      return;
    }

    // User has completed onboarding, allow direct access
    // (First conversation dialog is optional and won't block access)

    lastClickRef.current = now;
    isTogglingRef.current = true;
    try {
      console.log('üî∫ Starting session by orb press');
      await startConversation();
    } finally {
      setTimeout(() => { isTogglingRef.current = false; }, 400);
    }
  }, [isConnected, startConversation]);

  const features = [
    {
      icon: Heart,
      title: 'Preserve Your Voice',
      description: 'Record memories in your own words, capturing your essence.',
    },
    {
      icon: Clock,
      title: 'Timeline of Life',
      description: 'Organize memories chronologically to see your story unfold.',
    },
    {
      icon: Users,
      title: 'Share Selectively',
      description: 'Control who accesses different memories‚Äîfamily, friends, or private.',
    },
    {
      icon: Shield,
      title: 'Secure & Private',
      description: 'Encrypted storage in your personal sanctuary.',
    },
    {
      icon: Lock,
      title: 'Your Legacy',
      description: 'Create a lasting digital legacy for future generations.',
    },
    {
      icon: Sparkles,
      title: 'AI Companion',
      description: 'Solin helps reflect on memories and guide conversations.',
    }
  ];

  // Always show Solin interface for real authenticated users
  const shouldShowSolinInterface = true;

  if (shouldShowSolinInterface) {
    return (
      <div className="min-h-screen bg-background overflow-hidden relative">
        

        <div className="relative min-h-screen flex flex-col lg:flex-row items-start justify-center px-6 lg:px-12 py-10 gap-8 lg:gap-10">
          {/* Left Side - Solin Agent - Enhanced with modern design */}
          <div 
            className="flex-1 max-w-xl w-full h-[55vh] lg:h-[65vh] rounded-2xl border-[1.5px] p-4 sm:p-6 lg:p-8 flex flex-col justify-center animate-fade-in transition-all duration-300 hover:shadow-2xl"
            style={{ 
              background: 'linear-gradient(135deg, rgba(255,255,255,0.98), rgba(249,250,251,0.95))',
              backdropFilter: 'blur(20px)',
              borderColor: 'rgba(229, 231, 235, 0.6)',
              boxShadow: '0 8px 32px rgba(0, 0, 0, 0.08), 0 2px 8px rgba(0, 0, 0, 0.04)'
            }}
          >
            
            <div className="flex flex-col items-center gap-6">
              {/* View Mode Tabs - Enhanced design */}
              <div className="absolute top-4 right-4 flex gap-1 rounded-full p-1.5 border transition-all duration-300 z-10"
                style={{
                  background: 'linear-gradient(135deg, rgba(255,255,255,0.95), rgba(249,250,251,0.9))',
                  backdropFilter: 'blur(12px)',
                  borderColor: 'rgba(0,102,255,0.2)',
                  boxShadow: '0 4px 16px rgba(0, 102, 255, 0.12), 0 1px 3px rgba(0,0,0,0.06)'
                }}
              >
                <button
                  onClick={() => setViewMode('voice')}
                  className={`p-2.5 rounded-full transition-all duration-300 ${
                    viewMode === 'voice' 
                      ? 'text-white shadow-lg' 
                      : 'text-muted-foreground hover:bg-gray-100/80'
                  }`}
                  style={{
                    background: viewMode === 'voice' 
                      ? 'linear-gradient(135deg, #0066FF, #1E90FF)' 
                      : 'transparent',
                    transform: viewMode === 'voice' ? 'scale(1.05)' : 'scale(1)'
                  }}
                  title="Voice Agent"
                >
                  <Mic className="h-4 w-4" />
                </button>
                <button
                  onClick={() => setViewMode('particle')}
                  className={`p-2.5 rounded-full transition-all duration-300 ${
                    viewMode === 'particle' 
                      ? 'text-white shadow-lg' 
                      : 'text-muted-foreground hover:bg-gray-100/80'
                  }`}
                  style={{
                    background: viewMode === 'particle' 
                      ? 'linear-gradient(135deg, #0066FF, #1E90FF)' 
                      : 'transparent',
                    transform: viewMode === 'particle' ? 'scale(1.05)' : 'scale(1)'
                  }}
                  title="Particle Face"
                >
                  <Hexagon className="h-4 w-4" />
                </button>
              </div>

              <div className="relative mt-12 w-full flex justify-center">
                {viewMode === 'particle' ? (
                  <div className="w-full max-w-md mx-auto">
                    <ParticleFaceCanvas
                      particleCount={2000}
                      flowSpeed={1}
                      expression={isSpeaking ? 'speaking' : isConnected ? 'thinking' : 'neutral'}
                      ditherStyle="halftone"
                      holographicIntensity={0.7}
                      audioReactive={isConnected}
                    />
                  </div>
                ) : isConnecting ? (
                  <div className="w-40 h-40 flex items-center justify-center">
                    <Sparkles className="h-14 w-14 text-primary animate-pulse" />
                  </div>
                ) : (
                  <div className="w-full flex justify-center items-center">
                    <div className="w-[85%] max-w-[300px]">
                      <ModernVoiceAgent 
                        isActive={isConnected} 
                        isSpeaking={isSpeaking}
                        onClick={handleOrbPress}
                      />
                    </div>
                  </div>
                )}
              </div>

              <div className="text-center space-y-4 mt-12">
                {/* Personalized welcome message */}
                {user && (
                  <div className="mb-4">
                    <h2 className="text-2xl lg:text-3xl font-bold text-foreground mb-2">
                      Welcome, {displayFirstName}!
                    </h2>
                    <p className="text-base lg:text-lg text-muted-foreground">
                      Ready to continue your memory journey with Solin?
                    </p>
                  </div>
                )}
                
                {/* Smart conversation state indicator - Enhanced design */}
                {isConnected && (
                  <div className="space-y-2">
                    {conversationState.totalMemoriesSaved > 0 && (
                      <div className="text-xs px-3 py-1.5 rounded-full inline-block transition-all duration-300"
                        style={{
                          background: 'linear-gradient(135deg, rgba(0,102,255,0.12), rgba(30,144,255,0.08))',
                          border: '1px solid rgba(0,102,255,0.25)',
                          color: '#0066FF',
                          boxShadow: '0 2px 8px rgba(0,102,255,0.12)'
                        }}
                      >
                        üß† {conversationState.totalMemoriesSaved} memories saved ‚Ä¢ {conversationState.recentTopics.length} topics discussed
                      </div>
                    )}
                    {conversationState.userMemoryProfile && (
                      <div className="text-xs px-3 py-1.5 rounded-full inline-block transition-all duration-300"
                        style={{
                          background: 'linear-gradient(135deg, rgba(139,92,246,0.12), rgba(168,85,247,0.08))',
                          border: '1px solid rgba(139,92,246,0.25)',
                          color: '#8b5cf6',
                          boxShadow: '0 2px 8px rgba(139,92,246,0.12)'
                        }}
                      >
                        üéØ Intelligent prompting active ‚Ä¢ {conversationState.userMemoryProfile.totalMemories} total memories analyzed
                      </div>
                    )}
                  </div>
                )}
                
                {isConnected ? (
                  <div className="space-y-3">
                    {/* Conversation active indicator - Enhanced design */}
                    <div className="text-xs px-4 py-2 rounded-full transition-all duration-300"
                      style={{
                        background: 'linear-gradient(135deg, rgba(16,185,129,0.12), rgba(5,150,105,0.08))',
                        border: '1px solid rgba(16,185,129,0.25)',
                        color: '#10b981',
                        boxShadow: '0 2px 8px rgba(16,185,129,0.12)'
                      }}
                    >
                      üéôÔ∏è Conversation active ‚Äî Use the transcript box to save and end
                    </div>
                  </div>
                ) : (
                  <Button 
                    size="lg" 
                    onClick={startConversation} 
                    disabled={isConnecting} 
                    className="rounded-full text-white px-10 py-5 text-base font-semibold transition-all duration-300 hover:scale-105"
                    style={{
                      background: 'linear-gradient(135deg, #0066FF, #1E90FF)',
                      boxShadow: '0 8px 24px rgba(0, 102, 255, 0.35), 0 2px 8px rgba(0,0,0,0.08)'
                    }}
                  >
                    {isConnecting ? 'Connecting...' : 'Start Conversation'}
                  </Button>
                )}
              </div>
            </div>
          </div>

          {/* Right Side - Live Conversation Transcript - Enhanced modern design */}
          <div 
            className="flex-1 max-w-xl w-full h-[55vh] lg:h-[65vh] rounded-2xl border-[1.5px] p-5 flex flex-col overflow-hidden relative transition-all duration-300 hover:shadow-2xl"
            style={{ 
              background: 'linear-gradient(135deg, rgba(255,255,255,0.98), rgba(249,250,251,0.95))',
              backdropFilter: 'blur(20px)',
              borderColor: 'rgba(229, 231, 235, 0.6)',
              boxShadow: '0 8px 32px rgba(0, 0, 0, 0.08), 0 2px 8px rgba(0, 0, 0, 0.04)'
            }}
          >
            {/* Subtle background decoration */}
            <div className="absolute inset-0 bg-gradient-to-br from-blue-50/30 via-transparent to-purple-50/20 rounded-2xl pointer-events-none"></div>
            
            {/* Content container with relative positioning */}
            <div className="relative z-10 flex flex-col h-full">
              {/* Header with modern styling */}
              <div className="mb-4 pb-4 border-b" style={{ borderColor: 'rgba(229, 231, 235, 0.5)' }}>
                <h2 className="text-xl lg:text-2xl font-bold text-foreground">
                  Live Transcript
                </h2>
                <p className="text-sm lg:text-base text-muted-foreground mt-1">Real-time conversation with Solin</p>
                {!isConnected && (
                  <div className="mt-3 text-sm px-4 py-2 rounded-full inline-block transition-all duration-300"
                    style={{
                      background: 'linear-gradient(135deg, rgba(255,255,255,0.9), rgba(249,250,251,0.85))',
                      border: '1px solid rgba(229, 231, 235, 0.6)',
                      color: '#6b7280',
                      boxShadow: '0 2px 8px rgba(0,0,0,0.04)'
                    }}
                  >
                    üí¨ Share as much or as little as you'd like ‚Äî you can save and stop anytime
                  </div>
                )}
              </div>
              
              {/* Messages container */}
              <div className="flex-1 overflow-y-auto space-y-3 pr-2 mb-4">
                {conversationMessages.length === 0 ? (
                  <div className="h-full flex items-center justify-center">
                    <p className="text-muted-foreground text-base lg:text-lg text-center">
                      Your conversation will appear here...
                    </p>
                  </div>
                ) : (
                  conversationMessages.map((msg, idx) => (
                    <div
                      key={idx}
                      className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
                    >
                      <div
                        className={`max-w-[85%] rounded-lg px-4 py-3 transition-all duration-300 hover:scale-[1.02] ${
                          msg.role === 'user'
                            ? 'text-white rounded-br-md'
                            : 'text-foreground rounded-bl-md'
                        }`}
                        style={{
                          background: msg.role === 'user' 
                            ? 'linear-gradient(135deg, #0066FF, #1E90FF)' 
                            : 'linear-gradient(135deg, rgba(255,255,255,0.98), rgba(249,250,251,0.95))',
                          border: msg.role === 'user' ? 'none' : '1px solid rgba(229, 231, 235, 0.6)',
                          boxShadow: msg.role === 'user' 
                            ? '0 4px 12px rgba(0, 102, 255, 0.25), 0 1px 3px rgba(0,0,0,0.08)' 
                            : '0 2px 8px rgba(0,0,0,0.06), 0 1px 2px rgba(0,0,0,0.04)'
                        }}
                      >
                        <div className={`text-sm font-semibold mb-1 ${
                          msg.role === 'user' ? 'text-white/80' : 'opacity-70'
                        }`}>
                          {msg.role === 'user' ? 'You' : 'Solin'}
                        </div>
                        <div className="text-sm lg:text-base leading-relaxed whitespace-pre-wrap break-words">
                          {msg.text}
                          {idx === conversationMessages.length - 1 && msg.role === 'ai' && (
                            <span className="inline-block w-1 h-4 bg-primary ml-1 animate-pulse rounded-sm" />
                          )}
                        </div>
                      </div>
                    </div>
                  ))
                )}
              </div>
              
              {/* Save and End Button - Enhanced modern design */}
              {isConnected && (
                <div className="border-t pt-4 space-y-3" style={{ borderColor: 'rgba(229, 231, 235, 0.5)' }}>
                  {/* Helpful message with modern styling */}
                  <div className="text-center">
                    <div className="text-xs px-3 py-2 rounded-full inline-block transition-all duration-300"
                      style={{
                        background: 'linear-gradient(135deg, rgba(255,255,255,0.9), rgba(249,250,251,0.85))',
                        border: '1px solid rgba(229, 231, 235, 0.6)',
                        color: '#6b7280',
                        boxShadow: '0 2px 8px rgba(0,0,0,0.04)'
                      }}
                    >
                      üí¨ Click below anytime to save and end your conversation
                    </div>
                  </div>
                  
                  {/* Prominent Save & End Button - Enhanced design */}
                  <Button 
                    onClick={endConversation} 
                    size="lg"
                    disabled={isEndingConversation}
                    className="w-full rounded-xl text-white font-semibold transition-all duration-300 hover:scale-[1.02] disabled:opacity-70 disabled:hover:scale-100"
                    style={{
                      background: 'linear-gradient(135deg, #f59e0b, #f97316)',
                      boxShadow: '0 8px 24px rgba(245, 158, 11, 0.35), 0 2px 8px rgba(0,0,0,0.08)',
                      border: '2px solid rgba(255,255,255,0.2)'
                    }}
                  >
                    {isEndingConversation ? (
                      <>‚è≥ Waiting for Solin to finish speaking...</>
                    ) : (
                      <>‚ú® Save & End Conversation ‚ú®</>
                    )}
                  </Button>
                  
                  {/* Session info - Enhanced styling */}
                  {conversationState.totalMemoriesSaved > 0 && (
                    <div className="text-center">
                      <div className="text-xs px-3 py-1.5 rounded-full inline-block transition-all duration-300"
                        style={{
                          background: 'linear-gradient(135deg, rgba(0,102,255,0.1), rgba(30,144,255,0.08))',
                          border: '1px solid rgba(0,102,255,0.2)',
                          color: '#0066FF',
                          boxShadow: '0 2px 8px rgba(0,102,255,0.12)'
                        }}
                      >
                        üß† {conversationState.totalMemoriesSaved} memories saved ‚Ä¢ {conversationState.recentTopics.length} topics discussed
                      </div>
                    </div>
                  )}
                </div>
              )}
            </div>
          </div>
          
          {/* Intelligent Prompting Debug Panel */}
          {conversationState.suggestedQuestions.length > 0 && (
            <div 
              className="flex-1 max-w-xl bg-accent/5 rounded-lg border-[1.5px] p-4 max-h-64 overflow-y-auto"
              style={{ borderColor: 'hsl(var(--section-border))' }}
            >
              <div className="mb-3 pb-2 border-b" style={{ borderColor: 'hsl(var(--section-border))' }}>
                <h3 className="text-sm font-bold text-foreground flex items-center gap-2">
                  üß† Intelligent Suggestions
                  <span className="text-xs bg-accent/20 px-2 py-0.5 rounded-full">Debug Mode</span>
                </h3>
                <p className="text-xs text-muted-foreground mt-1">Solin can use these personalized questions</p>
              </div>
              <div className="space-y-2">
                {conversationState.suggestedQuestions.slice(0, 4).map((question, idx) => (
                  <div key={idx} className="text-xs bg-white/50 rounded p-2 border" style={{ borderColor: 'hsl(var(--section-border))' }}>
                    <span className="font-medium text-accent">{idx + 1}.</span> {question}
                  </div>
                ))}
              </div>
            </div>
          )}
          
        </div>
      </div>
    );
  }

  return (
    <div className="h-screen bg-background overflow-hidden">

      {/* Navigation */}
      <nav className="absolute top-0 left-0 right-0 z-40 bg-transparent border-b-[1.5px]" style={{ borderColor: 'hsl(var(--section-border))' }}>
        <div className="max-w-7xl mx-auto px-6 py-4 flex justify-between items-center">
          <div className="text-2xl font-bold">You, Remembered</div>
          <div className="flex gap-4 items-center">
            <Button variant="ghost" asChild>
              <Link to="/about">About</Link>
            </Button>
            <Button variant="ghost" asChild>
              <Link to="/how-it-works">How It Works</Link>
            </Button>
            <Button variant="ghost" asChild>
              <Link to="/mic-test" className="flex items-center gap-2">
                <Mic className="h-4 w-4" />
                Mic Test
              </Link>
            </Button>
            {!effectiveUser && (
              <Button variant="outline" size="sm" asChild>
                <Link to="/auth">Sign In</Link>
              </Button>
            )}
          </div>
        </div>
      </nav>

      {/* Single Screen Hero */}
      <div className="h-full flex items-center justify-center px-6">
        <div className="max-w-5xl w-full text-center space-y-6 animate-fade-in">
          <div className="space-y-4">
            <div className="inline-block px-4 py-2 rounded-full bg-primary/10 text-primary text-sm font-semibold">
              Digital Memory Sanctuary
            </div>
            
          <h1 className="text-5xl md:text-7xl font-bold tracking-tight leading-tight text-foreground">
            Replicate your presence
            <br />
            Make your story
            <br />
            <span className="bg-gradient-to-r from-primary to-accent bg-clip-text text-transparent">
              last forever
            </span>
          </h1>
            
            <p className="text-base md:text-lg text-muted-foreground max-w-2xl mx-auto">
              {effectiveUser ? `Welcome back, ${profile?.name?.split(' ')[0] || effectiveUser.user_metadata?.full_name?.split(' ')[0] || effectiveUser.email?.split('@')[0]}! Ready to continue your memory journey?` : 'Preserve your voice, stories, and values. Create a lasting legacy.'}
            </p>
          </div>
          
          <div className="flex flex-col sm:flex-row gap-4 justify-center">
            {effectiveUser ? (
              // Authenticated user - show voice agent button
              <>
                <Button 
                  size="lg" 
                  onClick={startConversation}
                  disabled={isConnecting || isConnected}
                  className="bg-primary hover:bg-primary/90 text-white px-8 py-5 rounded-full font-semibold hover:scale-105 transition-all"
                >
                  {isConnecting ? 'Connecting...' : isConnected ? 'Connected' : 'Start Conversation'}
                  <ArrowRight className="h-5 w-5 ml-2" />
                </Button>
                <Button 
                  size="sm" 
                  variant="outline"
                  asChild
                  className="px-6 py-3 rounded-full font-medium hover:scale-105 transition-all border-2 flex items-center gap-2"
                >
                  <Link to="/mic-test">
                    <Mic className="h-4 w-4" />
                    Test Microphone
                  </Link>
                </Button>
              </>
            ) : (
              // Unauthenticated user - show sign up options
              <>
                <Button 
                  size="lg" 
                  asChild
                  className="bg-primary hover:bg-primary/90 text-white px-8 py-5 rounded-full font-semibold hover:scale-105 transition-all"
                >
                  <Link to="/auth">
                    Create Account
                    <ArrowRight className="h-5 w-5 ml-2" />
                  </Link>
                </Button>
                <Button 
                  size="lg" 
                  variant="outline"
                  asChild
                  className="px-8 py-5 rounded-full font-semibold hover:scale-105 transition-all border-2"
                >
                  <Link to="/auth">
                    Sign In
                  </Link>
                </Button>
              </>
            )}
          </div>

          {/* Feature Pills */}
          <div className="flex flex-wrap gap-2 justify-center pt-3">
            {features.slice(0, 4).map((feature, index) => (
              <div 
                key={index} 
                className="px-4 py-2 rounded-full bg-card text-sm text-muted-foreground flex items-center gap-2 border-[1.5px]"
                style={{ borderColor: 'hsl(var(--section-border))' }}
              >
                <feature.icon className="h-4 w-4" />
                {feature.title}
              </div>
            ))}
          </div>
        </div>
      </div>
      
      {/* First Conversation Dialog */}
      <FirstConversationDialog 
        isOpen={showFirstConversation}
        onComplete={handleFirstConversationComplete}
      />
    </div>
  );
};

export default Index;
